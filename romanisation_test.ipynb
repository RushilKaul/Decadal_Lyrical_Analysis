{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpnjKTS0CPif",
        "outputId": "3a878762-a29d-48a2-b217-3774db7ba513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               Title           Film  Year  \\\n",
            "0        suquun dil ko mayassar gulosamar men nahiin  street singer  1938   \n",
            "1             kamasinii men dil pe gam kaa baar kyon  amrit manthan  1934   \n",
            "2  din niike biite jaate hain sumaran kar siyaara...  pooran bhagat  1933   \n",
            "3                 kaahe ko mohe chhere re beimanawaa         pukaar  1939   \n",
            "4                       suhaag kii raat aaii sajanii       adhikaar  1938   \n",
            "\n",
            "                     Singer         Composer              Lyricist  \\\n",
            "0  saigal kanan devi saigal  rai chand boral       aarzoo lakhnawi   \n",
            "1        shanta apte chorus  keshavrao bhole     veer muhammedpuri   \n",
            "2                    saigal        r c boral                   NaN   \n",
            "3      sardar akhtar chorus        mir sahab          kamal amrohi   \n",
            "4             pahari sanyal      timir baran  munshi arzoo rasheed   \n",
            "\n",
            "                                              Lyrics  \n",
            "0    suquun dil ko mayassar gulosamar men nahiin ...  \n",
            "1    kamasinii men dil pe gam kaa baar kyon 2 vaa...  \n",
            "2   aa aa  din niike biite jaate hain sumaran kar...  \n",
            "3       sa \\tkaahe ko mohe chhere re beimanawaa 2...  \n",
            "4       suhaag kii raat aaii sajanii kaahe bhare ...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from devatrans import DevaTrans\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv('./datasets/1930-39.csv')\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzGXJnSKCPih",
        "outputId": "7b9c67e1-c3ac-4261-9e8e-ac420d366166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               Title           Film  Year  \\\n",
            "0        suquun dil ko mayassar gulosamar men nahiin  street singer  1938   \n",
            "1             kamasinii men dil pe gam kaa baar kyon  amrit manthan  1934   \n",
            "2  din niike biite jaate hain sumaran kar siyaara...  pooran bhagat  1933   \n",
            "3                 kaahe ko mohe chhere re beimanawaa         pukaar  1939   \n",
            "4                       suhaag kii raat aaii sajanii       adhikaar  1938   \n",
            "\n",
            "                     Singer         Composer              Lyricist  \\\n",
            "0  saigal kanan devi saigal  rai chand boral       aarzoo lakhnawi   \n",
            "1        shanta apte chorus  keshavrao bhole     veer muhammedpuri   \n",
            "2                    saigal        r c boral                   NaN   \n",
            "3      sardar akhtar chorus        mir sahab          kamal amrohi   \n",
            "4             pahari sanyal      timir baran  munshi arzoo rasheed   \n",
            "\n",
            "                                              Lyrics  \\\n",
            "0    suquun dil ko mayassar gulosamar men nahiin ...   \n",
            "1    kamasinii men dil pe gam kaa baar kyon 2 vaa...   \n",
            "2   aa aa  din niike biite jaate hain sumaran kar...   \n",
            "3       sa \\tkaahe ko mohe chhere re beimanawaa 2...   \n",
            "4       suhaag kii raat aaii sajanii kaahe bhare ...   \n",
            "\n",
            "                                   lyrics_devanagari  \n",
            "0  [सुक़ून्, दिल्, क्o, मयस्सर्, गुल्oसमर्, मेन्, ...  \n",
            "1  [कमसिन्ी, मेन्, दिल्, पे, गम्, का, बार्, क्य्o...  \n",
            "2  [आ, आ, दिन्, न्ीके, ब्ीते, जाते, हैन्, सुमरन्,...  \n",
            "3  [स, काहे, क्o, म्oहे, च्हेरे, रे, बेइमनwआ, २, ...  \n",
            "4  [सुहाग्, क्ी, रात्, आी, सजन्ी, काहे, भरे, त्oर...  \n"
          ]
        }
      ],
      "source": [
        "# Create a DevaTrans object\n",
        "dt = DevaTrans()\n",
        "\n",
        "# Define a function for back-transliteration\n",
        "def back_transliterate(text):\n",
        "    # Back-transliterate the text\n",
        "    devanagari_text = dt.back_transliterate(input_type=\"sen\", from_convention=\"itrans\", sentence=text)\n",
        "    # Tokenize the text\n",
        "    doc = nlp(devanagari_text)\n",
        "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
        "    return tokens\n",
        "\n",
        "# Apply the function to the 'Lyrics' column\n",
        "data['lyrics_devanagari'] = data['Lyrics'].apply(back_transliterate)\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              Lyrics  \\\n",
            "0    suquun dil ko mayassar gulosamar men nahiin ...   \n",
            "1    kamasinii men dil pe gam kaa baar kyon 2 vaa...   \n",
            "2   aa aa  din niike biite jaate hain sumaran kar...   \n",
            "3       sa \\tkaahe ko mohe chhere re beimanawaa 2...   \n",
            "4       suhaag kii raat aaii sajanii kaahe bhare ...   \n",
            "\n",
            "                          lyrics_devanagari_velthuis  \n",
            "0  [सुqऊन्, दिल्, को, मयस्सर्, गुलोसमर्, मेन्, नह...  \n",
            "1  [कमसिनी, मेन्, दिल्, पे, गम्, का, बार्, क्योन्...  \n",
            "2  [आ, आ, दिन्, नीके, बीते, जाते, हैन्, सुमरन्, क...  \n",
            "3  [स, काहे, को, मोहे, छ्हेरे, रे, बेइमनwआ, २, का...  \n",
            "4  [सुहाग्, की, रात्, आई, सजनी, काहे, भरे, तोरे, ...  \n"
          ]
        }
      ],
      "source": [
        "# Define a function for back-transliteration using the \"velthuis\" convention\n",
        "def back_transliterate_velthuis(text):\n",
        "    # Back-transliterate the text\n",
        "    devanagari_text = dt.back_transliterate(input_type=\"sen\", from_convention=\"velthuis\", sentence=text)\n",
        "    # Tokenize the text\n",
        "    doc = nlp(devanagari_text)\n",
        "    tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
        "    return tokens\n",
        "\n",
        "# Apply the function to the 'Lyrics' column\n",
        "data['lyrics_devanagari_velthuis'] = data['Lyrics'].apply(back_transliterate_velthuis)\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "print(data[['Lyrics', 'lyrics_devanagari_velthuis']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NxWVX2WREwfO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 6.24MB/s]                    \n",
            "2024-03-26 15:28:36 INFO: Downloaded file to C:\\Users\\rushi\\stanza_resources\\resources.json\n",
            "2024-03-26 15:28:36 INFO: Downloading default packages for language: hi (Hindi) ...\n",
            "2024-03-26 15:28:37 INFO: File exists: C:\\Users\\rushi\\stanza_resources\\hi\\default.zip\n",
            "2024-03-26 15:28:39 INFO: Finished downloading models and saved to C:\\Users\\rushi\\stanza_resources\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "\n",
        "# Download the Hindi models for stanza\n",
        "stanza.download('hi')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 15:28:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 6.65MB/s]                    \n",
            "2024-03-26 15:28:39 INFO: Downloaded file to C:\\Users\\rushi\\stanza_resources\\resources.json\n",
            "2024-03-26 15:28:39 INFO: Loading these models for language: hi (Hindi):\n",
            "=============================\n",
            "| Processor | Package       |\n",
            "-----------------------------\n",
            "| tokenize  | hdtb          |\n",
            "| pos       | hdtb_charlm   |\n",
            "| lemma     | hdtb_nocharlm |\n",
            "=============================\n",
            "\n",
            "2024-03-26 15:28:39 INFO: Using device: cpu\n",
            "2024-03-26 15:28:39 INFO: Loading: tokenize\n",
            "2024-03-26 15:28:39 INFO: Loading: pos\n",
            "2024-03-26 15:28:40 INFO: Loading: lemma\n",
            "2024-03-26 15:28:40 INFO: Done loading processors!\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "If neither 'pretokenized' or 'no_ssplit' option is enabled, the input to the TokenizerProcessor must be a string or a Document object.  Got <class 'list'>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lemmas\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Apply the function to the 'lyrics_devanagari' column\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics_lemmatized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlyrics_devanagari\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_lemmas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics_devanagari\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics_lemmatized\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
            "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn[35], line 7\u001b[0m, in \u001b[0;36mextract_lemmas\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_lemmas\u001b[39m(text):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Process the text\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Extract lemmas and join them into a string\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(word\u001b[38;5;241m.\u001b[39mlemma \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msentences \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent\u001b[38;5;241m.\u001b[39mwords)\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stanza\\pipeline\\core.py:477\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stanza\\pipeline\\core.py:428\u001b[0m, in \u001b[0;36mPipeline.process\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mget(processor_name):\n\u001b[0;32m    427\u001b[0m         process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mbulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mprocess\n\u001b[1;32m--> 428\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
            "File \u001b[1;32mc:\\Users\\rushi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\stanza\\pipeline\\tokenize_processor.py:82\u001b[0m, in \u001b[0;36mTokenizeProcessor.process\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, document):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(document, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(document, doc\u001b[38;5;241m.\u001b[39mDocument) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretokenized\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_ssplit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))):\n\u001b[1;32m---> 82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf neither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretokenized\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_ssplit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option is enabled, the input to the TokenizerProcessor must be a string or a Document object.  Got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(document)))\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(document, doc\u001b[38;5;241m.\u001b[39mDocument):\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretokenized\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: If neither 'pretokenized' or 'no_ssplit' option is enabled, the input to the TokenizerProcessor must be a string or a Document object.  Got <class 'list'>"
          ]
        }
      ],
      "source": [
        "# Initialize the Hindi pipeline without the MWT processor\n",
        "nlp = stanza.Pipeline(lang='hi', processors='tokenize,pos,lemma')\n",
        "\n",
        "# Define a function to extract lemmas\n",
        "def extract_lemmas(text):\n",
        "    # Join the tokens into a string\n",
        "    text = ' '.join(text)\n",
        "    # Process the text\n",
        "    doc = nlp(text)\n",
        "    # Extract lemmas and join them into a string\n",
        "    lemmas = ' '.join(word.lemma for sent in doc.sentences for word in sent.words)\n",
        "    return lemmas\n",
        "\n",
        "# Apply the function to the 'lyrics_devanagari' column\n",
        "data['lyrics_lemmatized'] = data['lyrics_devanagari'].apply(extract_lemmas)\n",
        "\n",
        "print(data[['lyrics_devanagari', 'lyrics_lemmatized']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          lyrics_devanagari_velthuis  \\\n",
            "0    सुqऊन् दिल् को मयस्सर् गुलोसमर् मेन् नहीन् ज...   \n",
            "1    कमसिनी मेन् दिल् पे गम् का बार् क्योन् २ वा ...   \n",
            "2   आ आ  दिन् नीके बीते जाते हैन् सुमरन् कर् सिया...   \n",
            "3       स \\tकाहे को मोहे छ्हेरे रे बेइमनwआ २ \\tका...   \n",
            "4       सुहाग् की रात् आई सजनी काहे भरे तोरे नैना...   \n",
            "\n",
            "                          lyrics_lemmatized_velthuis  \n",
            "0  सुqऊन् दिल् को मयस्सर् गुलोसमर् मेन् नहीन् जो ...  \n",
            "1  कमसिनी मेन् दिल् पे गम् का बार् क्योन् २ वा यह...  \n",
            "2  आ आ दिन् नीके बीत जा हैन् सुमरन् कर् सियाराम् ...  \n",
            "3  स काहे को मोहे छ्हेरे रे बेइमनwआ २ काहे को मोह...  \n",
            "4  सुहाग् का रात् आ सजनी काहे भर तोरे नैना २ सुहा...  \n"
          ]
        }
      ],
      "source": [
        "# Apply the function to the 'lyrics_devanagari_velthuis' column\n",
        "data['lyrics_lemmatized_velthuis'] = data['lyrics_devanagari_velthuis'].apply(extract_lemmas)\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "print(data[['lyrics_devanagari_velthuis', 'lyrics_lemmatized_velthuis']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                   lyrics_devanagari  \\\n",
            "0    सुक़ून् दिल् क्o मयस्सर् गुल्oसमर् मेन् नह्ीन...   \n",
            "1    कमसिन्ी मेन् दिल् पे गम् का बार् क्य्oन् २ व...   \n",
            "2   आ आ  दिन् न्ीके ब्ीते जाते हैन् सुमरन् कर् सि...   \n",
            "3       स \\tकाहे क्o म्oहे च्हेरे रे बेइमनwआ २ \\t...   \n",
            "4       सुहाग् क्ी रात् आी सजन्ी काहे भरे त्oरे न...   \n",
            "\n",
            "                                   lyrics_lemmatized  lemmatization_change  \n",
            "0  सुक़ून् दिल् क्o मयस्सर् गुल्oसमर् मेन् नह्ीन् ...              0.035230  \n",
            "1  कमसिन्ी मेन् दिल् पे गम् का बार् क्य्oन् २ वा ...              0.056962  \n",
            "2  आ आ दिन् न्ीके ब्ीते जा हैन् सुमरन् कर् सियारा...              0.044547  \n",
            "3  स काहे क्o म्oहे च्हेरे रे बेइमनwआ २ काहे क्o ...              0.107383  \n",
            "4  सुहाग् क्ी रात् आी सजन्ी काहे भर त्oरे नैना २ ...              0.023026  \n"
          ]
        }
      ],
      "source": [
        "import Levenshtein as lev\n",
        "\n",
        "# Define a function to calculate the Levenshtein distance\n",
        "def calculate_change(original, lemmatized):\n",
        "    # Calculate the Levenshtein distance\n",
        "    distance = lev.distance(original, lemmatized)\n",
        "    # Normalize the distance by the length of the original text\n",
        "    normalized_distance = distance / max(len(original), 1)\n",
        "    return normalized_distance\n",
        "\n",
        "# Apply the function to the 'lyrics_devanagari' and 'lyrics_lemmatized' columns\n",
        "data['lemmatization_change'] = data.apply(lambda row: calculate_change(row['lyrics_devanagari'], row['lyrics_lemmatized']), axis=1)\n",
        "\n",
        "# Print the first 5 rows of the DataFrame\n",
        "print(data[['lyrics_devanagari', 'lyrics_lemmatized', 'lemmatization_change']].head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
