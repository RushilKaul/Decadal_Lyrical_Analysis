{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Clustering with K-Means\n",
    "In the present notebook we will use the [k-means algorithm](https://www.datascience.com/blog/k-means-clustering), a simple and popular __*unsupervised clustering*__ algorithm, to cluster the national anthems of the world into different groups.\n",
    "\n",
    "The objective of K-means is simple: group similar data points together and discover underlying patterns. To achieve this objective, K-means looks for a fixed defined number (k) of centroids in a dataset. A centroid refers to a cluster, which is a collection of data points aggregated together because of certain similarities with each other. The ‘means’ in the K-means refers to the averaging of the data; that is, finding the centroid. And the algorithm is said to be unsupervised because we have no prior knowledge with regards to the groups or classes of our dataset, that is, we will find the underlying groups in our dataset!\n",
    "\n",
    "Below we can visualize the algorithm. The green centroids matches the closest datapoints to each one and form clusters, then each centroid moves to the center of each respective group and matches again the closest datapoint to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Images/kmeans.gif \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "\n",
    "__1.__ Explore our collection of national anthems (corpus) <br>\n",
    "__2.__ Data Engineer the dataset to get the best perfomance from the K-means algorithm <br>\n",
    "__3.__ Run the algorithm many times, each time testing with a different number of clusters <br>\n",
    "__4.__ Use different metrics to visualize our results and find the best number of clusters (*ie. Why are a total of X clusters better than a total of Y clusters*) <br>\n",
    "__5.__ Cluster Analysis\n",
    "\n",
    "**Metrics Utilized for Determining the Best Number of K Cluters:**\n",
    "- [Elbow Method](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "- [Silhouette Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import json\n",
    "\n",
    "# Corpus Processing\n",
    "import re\n",
    "import nltk.corpus\n",
    "# from unidecode                        import unidecode\n",
    "from sklearn.feature_extraction.text  import TfidfVectorizer\n",
    "from sklearn.preprocessing            import normalize\n",
    "\n",
    "# K-Means\n",
    "from sklearn import cluster\n",
    "\n",
    "# Visualization and Analysis\n",
    "import matplotlib.pyplot  as plt\n",
    "import matplotlib.cm      as cm\n",
    "# import seaborn            as sns\n",
    "from sklearn.metrics                  import silhouette_samples, silhouette_score\n",
    "# from wordcloud                        import WordCloud\n",
    "\n",
    "# Map Viz\n",
    "# import folium\n",
    "#import branca.colormap as cm\n",
    "# from branca.element import Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10827\n",
      "100\n",
      "                                                  Title             Film  \\\n",
      "2804    ambuuvaa kii daaliidaalii jhuum rahii hai aalii        vidyapati   \n",
      "5951  he ho dhoye mahobe ghaat  dhobiyaa re dhobiyaa...           pukaar   \n",
      "1223  more anganaa men aaye aalii main chaal chaluun...        vidyapati   \n",
      "9234               prem nagar men banaauungii ghar main        chandidas   \n",
      "8878                 koii priit kii riit bataa do hamen  kaarwaanehayaat   \n",
      "\n",
      "      Year                             Singer                  Composer  \\\n",
      "2804  1937              kanan devi dhumi khan                 r c boral   \n",
      "5951  1939    sardar akhtar male voice chorus                 mir sahab   \n",
      "1223  1937                         kanan devi                 r c boral   \n",
      "9234  1934                  saigal uma shashi                 r c boral   \n",
      "8878  1935  saigal pahadi sanyal female voice  mihir kiran bhattacharya   \n",
      "\n",
      "            Lyricist                                             Lyrics  \n",
      "2804    kedar sharma  \\tkaa\\tambuuvaa kii daaliidaalii\\tjhuum rahii ...  \n",
      "5951    kamal amrohi  \\tko\\the ho dhoye mahobe ghaat\\the ho dhoye ma...  \n",
      "1223    kedar sharma  \\tanganaa men aaye aalii main chaal chaluun ma...  \n",
      "9234  aga h kashmiri   u\\tprem nagar men banaauungii ghar main sajak...  \n",
      "8878             NaN   koii priit kii riit bataa do hamen koii man k...  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "data = pd.read_csv('./lyrics_p.csv')\n",
    "\n",
    "# Filter rows for each decade and sample 100 rows from each\n",
    "random_samples = []\n",
    "\n",
    "# Decades to consider\n",
    "decades = [(1930, 1939), (1940, 1949), (1950, 1959) ,(1960,1969),(1970,1979),(1980,1989),(1990,1999),(2000,2009)]\n",
    "\n",
    "for decade in decades:\n",
    "    start_year, end_year = decade\n",
    "    decade_data = data[(data['Year'] >= start_year) & (data['Year'] <= end_year)]\n",
    "    sample = decade_data.sample(n=100)  # Sampling 100 rows from each decade\n",
    "    random_samples.append(sample)\n",
    "    \n",
    "print(len(data))\n",
    "print(len(random_samples[0]))\n",
    "\n",
    "# data = data.sample(n=100, random_state=42)\n",
    "random_samples = pd.concat(random_samples)\n",
    "data = random_samples\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces from data\n",
    "# data['Lyrics'] = data['Lyrics'].str.strip()\n",
    "# Replace tab spaces with 2 spaces\n",
    "# data['Lyrics'] = data['Lyrics'].str.replace(r'\\t', '  ', regex=True)\n",
    "# Replace more than two spaces with two spaces\n",
    "# data['Lyrics'] = data['Lyrics'].str.replace(r'\\s{3,}', '  ', regex=True)\n",
    "\n",
    "# print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "['\\tkaa\\tambuuvaa kii daaliidaalii\\tjhuum rahii hai aalii\\tjhuum rahii hai aalii\\tdhu\\tmain pii kar mad kii pyaalii\\tyuun chaal chaluun matawaalii\\tyuun chaal chaluun matawaalii\\tkaa\\tambuuvaa kii daaliidaalii\\tjhuum rahii hai aalii\\tjhuum rahii hai aalii\\tmatawaalii\\tmatawaalii\\tmatawaalii\\tdhu\\tmatawaalii\\tmatawaalii\\tmatawaalii\\tmain chaal chaluun matawaalii kaa\\tmain chaal chaluun matawaalii dhu\\tdaraa dar dar dar dar dar da kaa\\tdaraa dar dar dar dar dar da\\tmore anganaa men aaye aaliiaalii\\tmain chaal chaluun matawaalii\\tjhuum rahii hai aalii\\tambuuvaa kii daalii\\tjhuum rahii hai aalii\\tambuuvaa kii daalii\\tambuuvaa kii daaliidaalii\\tjhuum rahii hai aalii\\tjhuum rahii hai aalii\\tdo\\tmatawaalii\\tmatawaalii\\tmatawaalii\\tmatawaalii\\tmatawaalii\\tmatawaalii\\tmain chaal chaluun matawaalii\\tmain chaal chaluun matawaalii\\tmore anganaa men aaye aaliiaalii\\tmain chaal chaluun matawaalii\\tjhuum rahii hai aalii\\tambuuvaa kii daalii\\tjhuum rahii hai aalii\\tambuuvaa kii daalii\\tambuuvaa kii daaliidaalii\\tjhuum rahii hai aalii ', '\\tko\\the ho dhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\tsa\\tdhobiyaa re dhobiyaa\\tkahaan tumhaaro\\tyaunan kaunan\\tkahaan tumhaaro ghaat\\the ho kahaan tumhaaro ghaat\\the ho kahaan tumhaaro ghaat\\tko\\tmirazaapur men\\taunan kaunan\\tkabhii hamaaro ghaat\\the ho kabhii hamaaro ghaat\\the ho kabhii hamaaro ghaat\\the ho kabhii hamaaro ghaat\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\tdhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\tchaandii kii nadiyaa men dhoban kii angiyaa\\tchaandii kii nadiyaa men dhoban kii angiyaa\\tdhoye re dhoye re masmas dhotiyaa\\tdhoye re dhoye re masmas dhotiyaa\\tchamcham chamakegii angiyaa pahan ke\\tchamcham chamakegii angiyaa pahan ke\\tbarasenge chundarii pe taare gagan ke\\tbarasenge chundarii pe taare gagan ke\\tko\\tdhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\tsajo tumhaaro\\tpyaaro joban\\tsajo tumhaaro ghaat\\the ho sajo tumhaaro ghaat\\the ho sajo tumhaaro ghaat\\the ho sajo tumhaaro ghaat\\tsa\\thamaraa tumharaa bandhe re painjan\\thamaraa tumharaa bandhe re painjan\\tchalen niraale thaath\\the ho chalen niraale thaath\\the ho chalen niraale thaath\\tko\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\tdhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\tsa\\tho more dhobiyaa kii pagadii puraanii\\tho more dhobiyaa kii pagadii puraanii\\tpagadii puraanii kyuun dhoye mahaaraanii\\tpagadii puraanii kyuun dhoye mahaaraanii\\tdhobiyaa kii godii men raanii simat gayii\\tdhobiyaa kii godii men raanii simat gayii\\tko\\tdhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\the ho dhoye mahobe ghaat\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\thaiyo raam\\tdhoye mahobe ghaat ', '\\tanganaa men aaye aalii main chaal chaluun matawaalii\\tanganaa men aaye aalii main chaal chaluun matawaalii\\tanganaa men aaye aa\\tai sunatii ho sunosuno un un mujhase kah rahe hain haan ye kaise giit gaa rahii hai kyuun jii ye to bade achchhe giit hain achchhe giit hain raadhaakishan ke prem ke giit hain raadhaakishan ke prem ke giit hain sunaao to suniyegaa baithiye baithiye aaiiye baithiye uh uh uh uh uh ah ha ha ha ha ha suniye raadhikaa apanii sahelii se kah rahii hai ke jab shrii krishn\\tmore anganaa men aaye aalii main chaal chaluun matawaalii anganaa men aaye aa\\tjab aanchal hamaraa pakade ham hanshans unase bache\\tjab aanchal hamaraa pakade ham hanshans unase bache\\tcholii pe najariyaa aa jaaye cholii pe najariyaa jaaye morii chunarii lipat mose jaaye haan haan chunarii lipat mose\\tbas bas rahane do tum mithilaa kii bahuubetiyon kaa satyaanaas karake chhodogii cholii pe uf\\tjii zaraa sun to liijiye aur kyaa ab bhii kuchh baakii hai hum\\two aur badhen more paiyaan paden kahen maano baat hamaarii\\two aur badhen more paiyaan paden kahen maano baat hamaarii\\tmain aah bharuun mukh pher kahuun\\tmain aah bharuun mukh pher kahuun\\tnahiin maanuungii baat tehaarii haan nahiin maanuungii baat tehaarii nahiin maanuungii baat tehaarii tehaarii nahiin maanuungii baat tohaarii haan nahiin maanuungii baat tehaarii tumhaarii ', ' u\\tprem nagar men banaauungii ghar main sajake ghar sansaar\\tprem nagar men banaauungii ghar main sajake ghar sansaar\\tprem kaa aangan prem kii chhat aur prem ke honge dvaar\\tprem kaa aangan prem kii chhat aur prem ke honge dvaar\\tprem nagar men banaauungii ghar main sajake ghar sansaar\\tprem nagar men banaauungii ghar main sajake ghar sansaar\\ts\\tprem sakhaa ho prem padausii\\tprem men sukh kaa saar prem men duhkh kaa saar\\tprem sakhaa ho prem padausii\\tprem men duhkh kaa saar prem men sukh kaa saar\\tprem ke sang bitaayenge jiivan\\tprem ke sang bitaayenge jiivan\\tprem hii praanaadhaar\\tprem ke sang bitaayenge jiivan prem hii praanaadhaar\\tprem sakhaa ho prem padausii\\tprem men sukh kaa saar prem men duhkh kaa saar\\tprem ke sang bitaayenge jiivan\\tprem ke sang bitaayenge jiivan\\tprem hii praanaadhaar\\tu\\tprem sudhaa se snaan karuungii\\tprem se hogaa shringaar prem se hogaa shringaar\\tprem se hogaa shringaar prem se hogaa shringaar\\ts\\tprem hii karm hai prem hii dharm hai\\tprem hii sant vichaar prem hii sant vichaar\\tprem hii sant vichaar prem hii sant vichaar\\tu\\tprem nagar men banaauungii ghar main sajake ghar sansaar ', ' koii priit kii riit bataa do hamen koii man kaa miit milaa do hamen koii aisaa giit sunaa do hamen khil jaaye dil se dil kii kalii\\t koii priit kii riit bataa do hamen koii man kaa miit milaa do hamen koii aisaa giit sunaa do hamen khil jaaye dil se dil kii kalii\\tbanawaasii miit kahaan jaane paradesii priit kahaan jaane ham aisaa giit kahaan jaane\\tbanawaasii miit kahaan jaane paradesii priit kahaan jaane ham aisaa giit kahaan jaane\\tkhil jaaye dil se dil kii kalii\\tkhil jaaye dil se dil kii kalii\\tyahaan dil kii kalii kabahii na khilii\\tyahaan dil kii kalii kabahii na khilii\\tye sab shaharon ke dhande hain ye hirsohawas ke phande hain ham to sailaanii bande hain ham priit kii riit kahaan jaane\\tye sab shaharon ke dhande hain ye hirsohawas ke phande hain ham to sailaanii bande hain ham priit kii riit kahaan jaane\\tdil jangal hii men bahalataa hai yahaan honthon pe giit machalataa hai\\tdil jangal hii men bahalataa hai yahaan honthon pe giit machalataa hai\\tyahaan prem kaa saagar chalataa hai\\tyahaan prem kaa saagar chalataa hai\\thamen priit kii riit bataa de koii hamen aisaa giit sunaa de koii\\thamen priit kii riit bataa de koii hamen aisaa giit sunaa de koii\\tkhil jaaye dil se dil kii kalii\\tkhil jaaye dil se dil kii kalii\\tyahaan dil kii kalii to kabhii naa khilii\\tyahaan dil kii kalii to kabhii naa khilii\\t']\n",
      "800\n",
      "['\\tका\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम् रही है आली\\tधु\\tमैन् पी कर् मद् की प्याली\\tयून् चाल् चलून् मतवाली\\tयून् चाल् चलून् मतवाली\\tका\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम् रही है आली\\tमतवाली\\tमतवाली\\tमतवाली\\tधु\\tमतवाली\\tमतवाली\\tमतवाली\\tमैन् चाल् चलून् मतवाली का\\tमैन् चाल् चलून् मतवाली धु\\tदरा दर् दर् दर् दर् दर् द का\\tदरा दर् दर् दर् दर् दर् द\\tमोरे अन्गना मेन् आये आलीआली\\tमैन् चाल् चलून् मतवाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम् रही है आली\\tदो\\tमतवाली\\tमतवाली\\tमतवाली\\tमतवाली\\tमतवाली\\tमतवाली\\tमैन् चाल् चलून् मतवाली\\tमैन् चाल् चलून् मतवाली\\tमोरे अन्गना मेन् आये आलीआली\\tमैन् चाल् चलून् मतवाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tअम्बूवा की दालीदाली\\tझूम् रही है आली ', '\\tको\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे घात्\\tस\\tधोबिया रे धोबिया\\tकहान् तुम्हारो\\tयौनन् कौनन्\\tकहान् तुम्हारो घात्\\tहे हो कहान् तुम्हारो घात्\\tहे हो कहान् तुम्हारो घात्\\tको\\tमिरज़ापुर् मेन्\\tऔनन् कौनन्\\tकभी हमारो घात्\\tहे हो कभी हमारो घात्\\tहे हो कभी हमारो घात्\\tहे हो कभी हमारो घात्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tधोये महोबे घात्\\tहे हो धोये महोबे घात्\\tचान्दी की नदिया मेन् धोबन् की अन्गिया\\tचान्दी की नदिया मेन् धोबन् की अन्गिया\\tधोये रे धोये रे मस्मस् धोतिया\\tधोये रे धोये रे मस्मस् धोतिया\\tचम्चम् चमकेगी अन्गिया पहन् के\\tचम्चम् चमकेगी अन्गिया पहन् के\\tबरसेन्गे चुन्दरी पे तारे गगन् के\\tबरसेन्गे चुन्दरी पे तारे गगन् के\\tको\\tधोये महोबे घात्\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे घात्\\tसजो तुम्हारो\\tप्यारो जोबन्\\tसजो तुम्हारो घात्\\tहे हो सजो तुम्हारो घात्\\tहे हो सजो तुम्हारो घात्\\tहे हो सजो तुम्हारो घात्\\tस\\tहमरा तुम्हरा बन्धे रे पैन्जन्\\tहमरा तुम्हरा बन्धे रे पैन्जन्\\tचलेन् निराले थाथ्\\tहे हो चलेन् निराले थाथ्\\tहे हो चलेन् निराले थाथ्\\tको\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tधोये महोबे घात्\\tहे हो धोये महोबे घात्\\tस\\tहो मोरे धोबिया की पगदी पुरानी\\tहो मोरे धोबिया की पगदी पुरानी\\tपगदी पुरानी क्यून् धोये महारानी\\tपगदी पुरानी क्यून् धोये महारानी\\tधोबिया की गोदी मेन् रानी सिमत् गयी\\tधोबिया की गोदी मेन् रानी सिमत् गयी\\tको\\tधोये महोबे घात्\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे घात्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tधोये महोबे घात् ', '\\tअन्गना मेन् आये आली मैन् चाल् चलून् मतवाली\\tअन्गना मेन् आये आली मैन् चाल् चलून् मतवाली\\tअन्गना मेन् आये आ\\tऐ सुनती हो सुनोसुनो उन् उन् मुझसे कह् रहे हैन् हान् ये कैसे गीत् गा रही है क्यून् जी ये तो बदे अच्छे गीत् हैन् अच्छे गीत् हैन् राधाकिशन् के प्रेम् के गीत् हैन् राधाकिशन् के प्रेम् के गीत् हैन् सुनाओ तो सुनियेगा बैथिये बैथिये आईये बैथिये उह् उह् उह् उह् उह् अह् ह ह ह ह ह सुनिये राधिका अपनी सहेली से कह् रही है के जब् श्री क्रिश्न्\\tमोरे अन्गना मेन् आये आली मैन् चाल् चलून् मतवाली अन्गना मेन् आये आ\\tजब् आन्चल् हमरा पकदे हम् हन्शन्स् उनसे बचे\\tजब् आन्चल् हमरा पकदे हम् हन्शन्स् उनसे बचे\\tचोली पे नजरिया आ जाये चोली पे नजरिया जाये मोरी चुनरी लिपत् मोसे जाये हान् हान् चुनरी लिपत् मोसे\\tबस् बस् रहने दो तुम् मिथिला की बहूबेतियोन् का सत्यानास् करके छोदोगी चोली पे उफ़्\\tजी ज़रा सुन् तो लीजिये और् क्या अब् भी कुछ् बाकी है हुम्\\tवो और् बधेन् मोरे पैयान् पदेन् कहेन् मानो बात् हमारी\\tवो और् बधेन् मोरे पैयान् पदेन् कहेन् मानो बात् हमारी\\tमैन् आह् भरून् मुख् फेर् कहून्\\tमैन् आह् भरून् मुख् फेर् कहून्\\tनहीन् मानून्गी बात् तेहारी हान् नहीन् मानून्गी बात् तेहारी नहीन् मानून्गी बात् तेहारी तेहारी नहीन् मानून्गी बात् तोहारी हान् नहीन् मानून्गी बात् तेहारी तुम्हारी ', ' उ\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर् सन्सार्\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर् सन्सार्\\tप्रेम् का आन्गन् प्रेम् की छत् और् प्रेम् के होन्गे द्वार्\\tप्रेम् का आन्गन् प्रेम् की छत् और् प्रेम् के होन्गे द्वार्\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर् सन्सार्\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर् सन्सार्\\tस्\\tप्रेम् सखा हो प्रेम् पदौसी\\tप्रेम् मेन् सुख् का सार् प्रेम् मेन् दुह्ख् का सार्\\tप्रेम् सखा हो प्रेम् पदौसी\\tप्रेम् मेन् दुह्ख् का सार् प्रेम् मेन् सुख् का सार्\\tप्रेम् के सन्ग् बितायेन्गे जीवन्\\tप्रेम् के सन्ग् बितायेन्गे जीवन्\\tप्रेम् ही प्रानाधार्\\tप्रेम् के सन्ग् बितायेन्गे जीवन् प्रेम् ही प्रानाधार्\\tप्रेम् सखा हो प्रेम् पदौसी\\tप्रेम् मेन् सुख् का सार् प्रेम् मेन् दुह्ख् का सार्\\tप्रेम् के सन्ग् बितायेन्गे जीवन्\\tप्रेम् के सन्ग् बितायेन्गे जीवन्\\tप्रेम् ही प्रानाधार्\\tउ\\tप्रेम् सुधा से स्नान् करून्गी\\tप्रेम् से होगा श्रिन्गार् प्रेम् से होगा श्रिन्गार्\\tप्रेम् से होगा श्रिन्गार् प्रेम् से होगा श्रिन्गार्\\tस्\\tप्रेम् ही कर्म् है प्रेम् ही धर्म् है\\tप्रेम् ही सन्त् विचार् प्रेम् ही सन्त् विचार्\\tप्रेम् ही सन्त् विचार् प्रेम् ही सन्त् विचार्\\tउ\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर् सन्सार् ', ' कोई प्रीत् की रीत् बता दो हमेन् कोई मन् का मीत् मिला दो हमेन् कोई ऐसा गीत् सुना दो हमेन् खिल् जाये दिल् से दिल् की कली\\t कोई प्रीत् की रीत् बता दो हमेन् कोई मन् का मीत् मिला दो हमेन् कोई ऐसा गीत् सुना दो हमेन् खिल् जाये दिल् से दिल् की कली\\tबनवासी मीत् कहान् जाने परदेसी प्रीत् कहान् जाने हम् ऐसा गीत् कहान् जाने\\tबनवासी मीत् कहान् जाने परदेसी प्रीत् कहान् जाने हम् ऐसा गीत् कहान् जाने\\tखिल् जाये दिल् से दिल् की कली\\tखिल् जाये दिल् से दिल् की कली\\tयहान् दिल् की कली कबही न खिली\\tयहान् दिल् की कली कबही न खिली\\tये सब् शहरोन् के धन्दे हैन् ये हिर्सोहवस् के फन्दे हैन् हम् तो सैलानी बन्दे हैन् हम् प्रीत् की रीत् कहान् जाने\\tये सब् शहरोन् के धन्दे हैन् ये हिर्सोहवस् के फन्दे हैन् हम् तो सैलानी बन्दे हैन् हम् प्रीत् की रीत् कहान् जाने\\tदिल् जन्गल् ही मेन् बहलता है यहान् होन्थोन् पे गीत् मचलता है\\tदिल् जन्गल् ही मेन् बहलता है यहान् होन्थोन् पे गीत् मचलता है\\tयहान् प्रेम् का सागर् चलता है\\tयहान् प्रेम् का सागर् चलता है\\tहमेन् प्रीत् की रीत् बता दे कोई हमेन् ऐसा गीत् सुना दे कोई\\tहमेन् प्रीत् की रीत् बता दे कोई हमेन् ऐसा गीत् सुना दे कोई\\tखिल् जाये दिल् से दिल् की कली\\tखिल् जाये दिल् से दिल् की कली\\tयहान् दिल् की कली तो कभी ना खिली\\tयहान् दिल् की कली तो कभी ना खिली\\t']\n",
      "Data length:  800\n",
      "800\n",
      "0    \\tका\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझू...\n",
      "1    \\tको\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे ...\n",
      "2    \\tअन्गना मेन् आये आली मैन् चाल् चलून् मतवाली\\t...\n",
      "3     उ\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर...\n",
      "4     कोई प्रीत् की रीत् बता दो हमेन् कोई मन् का मी...\n",
      "dtype: object\n",
      "                                               Title             Film  Year  \\\n",
      "0    ambuuvaa kii daaliidaalii jhuum rahii hai aalii        vidyapati  1937   \n",
      "1  he ho dhoye mahobe ghaat  dhobiyaa re dhobiyaa...           pukaar  1939   \n",
      "2  more anganaa men aaye aalii main chaal chaluun...        vidyapati  1937   \n",
      "3               prem nagar men banaauungii ghar main        chandidas  1934   \n",
      "4                 koii priit kii riit bataa do hamen  kaarwaanehayaat  1935   \n",
      "\n",
      "                              Singer                  Composer  \\\n",
      "0              kanan devi dhumi khan                 r c boral   \n",
      "1    sardar akhtar male voice chorus                 mir sahab   \n",
      "2                         kanan devi                 r c boral   \n",
      "3                  saigal uma shashi                 r c boral   \n",
      "4  saigal pahadi sanyal female voice  mihir kiran bhattacharya   \n",
      "\n",
      "         Lyricist                                             Lyrics  \\\n",
      "0    kedar sharma  \\tkaa\\tambuuvaa kii daaliidaalii\\tjhuum rahii ...   \n",
      "1    kamal amrohi  \\tko\\the ho dhoye mahobe ghaat\\the ho dhoye ma...   \n",
      "2    kedar sharma  \\tanganaa men aaye aalii main chaal chaluun ma...   \n",
      "3  aga h kashmiri   u\\tprem nagar men banaauungii ghar main sajak...   \n",
      "4             NaN   koii priit kii riit bataa do hamen koii man k...   \n",
      "\n",
      "                                          Devanagari  \n",
      "0  \\tका\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझू...  \n",
      "1  \\tको\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे ...  \n",
      "2  \\tअन्गना मेन् आये आली मैन् चाल् चलून् मतवाली\\t...  \n",
      "3   उ\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर...  \n",
      "4   कोई प्रीत् की रीत् बता दो हमेन् कोई मन् का मी...  \n"
     ]
    }
   ],
   "source": [
    "from indic_transliteration import sanscript\n",
    "def roman_to_devanagari(text_list):\n",
    "    devanagari_sentences = []\n",
    "    for text in text_list:\n",
    "        # Transliterate Romanized Hindi to Devanagari\n",
    "        devanagari_text = sanscript.transliterate(text, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_sentences.append(devanagari_text)\n",
    "    return devanagari_sentences\n",
    "\n",
    "# Test the function\n",
    "roman_sentences = data['Lyrics'].to_list()\n",
    "print(len(roman_sentences))\n",
    "print(roman_sentences[:5])\n",
    "\n",
    "devanagari_sentences = roman_to_devanagari(roman_sentences)\n",
    "print(len(devanagari_sentences))\n",
    "print(devanagari_sentences[:5])\n",
    "\n",
    "# Convert the list to a pandas Series\n",
    "devanagari_series = pd.Series(devanagari_sentences)\n",
    "print(\"Data length: \", len(data))\n",
    "print(len(devanagari_series))\n",
    "print(devanagari_series.head())\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "# Add the series as a new column in the DataFrame\n",
    "data['Devanagari'] = devanagari_series\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushil/.local/lib/python3.10/site-packages/spello/model.py:301: UserWarning: This model was saved on spell<1.3.0. As such due to a bug in previous versions, none of customisations made to the config at the time of training were saved along with the model. It is recommended to load the model, apply all required customizations to config and save it again. E.g.\n",
      "\n",
      "from spello.model import SpellCorrectionModel \n",
      "sp = SpellCorrectionModel(language='en')  \n",
      "sp.load('/home/ubuntu/model.pkl')\n",
      "sp.config.min_length_for_spellcorrection = 4 # default is 3\n",
      "sp.config.max_length_for_spellcorrection = 12 # default is 15\n",
      "sp.save(model_save_dir='/home/ubuntu/')\n",
      "\n",
      "After this the model will load without any warnings\n",
      "\n",
      "  warnings.warn(\"This model was saved on spell<1.3.0. As such due to a bug in previous versions, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      \\tका\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझू...\n",
      "1      \\tको\\tहे हो धोये महोबे घात्\\tहे हो धोये महोबे ...\n",
      "2      \\tअन्गना मेन् आये आली मैन् चाल् चलून् मतवाली\\t...\n",
      "3       उ\\tप्रेम् नगर् मेन् बनाऊन्गी घर् मैन् सजके घर...\n",
      "4       कोई प्रीत् की रीत् बता दो हमेन् कोई मन् का मी...\n",
      "                             ...                        \n",
      "795     इश्क़् की ज़िन्दा निशानी है ये सदियोन् पुरानी क...\n",
      "796     मेरी नीन्द् चुरा ले मेरा चैन् चुरा ले दिल् मे...\n",
      "797     पम् पम् पम् पम् प र र र र ऐली रे ऐली क्या है ...\n",
      "798     ओ ये ये ये कोई मेरी जान् ले ले तदपता हुआ यून्...\n",
      "799     यार् तेरी बेवफ़ाई का हमको ज़रा सा गम् नहीन्\\tयह...\n",
      "Name: Devanagari, Length: 800, dtype: object 0      का\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम्...\n",
      "1      को\\tहे हो धोखे महोबा घात्\\tहे हो धोखे महोबा घा...\n",
      "2      अन्ना मेन आये आली मेन चाल चलने मतवाली\\tअन्गना ...\n",
      "3      उ\\tप्रेम् नगर' मेन बनाऊंगा घर) मैन सके घर) सन्...\n",
      "4      कोई प्रीति की रीति बता दो हमें कोई मन का मीता ...\n",
      "                             ...                        \n",
      "795    इश्यू की निन्दा निशानी है ये सदियों पुरानी कहा...\n",
      "796    मेरी निन्दा चुरा ले मेरा चैनल चुरा ले दिल मेन ...\n",
      "797    पम्प पम् पम्प पम् प र र र र ऐली रे ऐली क्या है...\n",
      "798    ओ ये ये ये कोई मेरी जान ले ले पता हुआ यन् मुझे...\n",
      "799    यार तेरी बेवफ़ाई का हमको करा सा गमन नहीन्\\tयहान...\n",
      "Name: Devanagari_spell_check, Length: 800, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# # Apply the function to the 'Lyrics' column\n",
    "# data['lyrics_devanagari'] = data['Lyrics'].apply(back_transliterate)\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "# print((data))\n",
    "\n",
    "from spello.model import SpellCorrectionModel\n",
    "sp = SpellCorrectionModel(language='hi')\n",
    "sp.load('hi.pkl')\n",
    "temp = data['Devanagari'].apply(sp.spell_correct)\n",
    "data['Devanagari_spell_check'] = temp.apply(lambda x: x['spell_corrected_text'])\n",
    "print(data['Devanagari'], data['Devanagari_spell_check'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rushil/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.1MB/s]                    \n",
      "2024-04-26 19:42:49 INFO: Downloaded file to /home/rushil/stanza_resources/resources.json\n",
      "2024-04-26 19:42:49 INFO: Downloading default packages for language: hi (Hindi) ...\n",
      "2024-04-26 19:42:50 INFO: File exists: /home/rushil/stanza_resources/hi/default.zip\n",
      "2024-04-26 19:42:51 INFO: Finished downloading models and saved to /home/rushil/stanza_resources\n",
      "2024-04-26 19:42:51 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 18.7MB/s]                    \n",
      "2024-04-26 19:42:51 INFO: Downloaded file to /home/rushil/stanza_resources/resources.json\n",
      "2024-04-26 19:42:52 INFO: Loading these models for language: hi (Hindi):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | hdtb          |\n",
      "| pos       | hdtb_charlm   |\n",
      "| lemma     | hdtb_nocharlm |\n",
      "=============================\n",
      "\n",
      "2024-04-26 19:42:52 INFO: Using device: cpu\n",
      "2024-04-26 19:42:52 INFO: Loading: tokenize\n",
      "2024-04-26 19:42:52 INFO: Loading: pos\n",
      "2024-04-26 19:42:52 INFO: Loading: lemma\n",
      "2024-04-26 19:42:52 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 lines.\n",
      "Processed 2 lines.\n",
      "Processed 3 lines.\n",
      "Processed 4 lines.\n",
      "Processed 5 lines.\n",
      "Processed 6 lines.\n",
      "Processed 7 lines.\n",
      "Processed 8 lines.\n",
      "Processed 9 lines.\n",
      "Processed 10 lines.\n",
      "Processed 11 lines.\n",
      "Processed 12 lines.\n",
      "Processed 13 lines.\n",
      "Processed 14 lines.\n",
      "Processed 15 lines.\n",
      "Processed 16 lines.\n",
      "Processed 17 lines.\n",
      "Processed 18 lines.\n",
      "Processed 19 lines.\n",
      "Processed 20 lines.\n",
      "Processed 21 lines.\n",
      "Processed 22 lines.\n",
      "Processed 23 lines.\n",
      "Processed 24 lines.\n",
      "Processed 25 lines.\n",
      "Processed 26 lines.\n",
      "Processed 27 lines.\n",
      "Processed 28 lines.\n",
      "Processed 29 lines.\n",
      "Processed 30 lines.\n",
      "Processed 31 lines.\n",
      "Processed 32 lines.\n",
      "Processed 33 lines.\n",
      "Processed 34 lines.\n",
      "Processed 35 lines.\n",
      "Processed 36 lines.\n",
      "Processed 37 lines.\n",
      "Processed 38 lines.\n",
      "Processed 39 lines.\n",
      "Processed 40 lines.\n",
      "Processed 41 lines.\n",
      "Processed 42 lines.\n",
      "Processed 43 lines.\n",
      "Processed 44 lines.\n",
      "Processed 45 lines.\n",
      "Processed 46 lines.\n",
      "Processed 47 lines.\n",
      "Processed 48 lines.\n",
      "Processed 49 lines.\n",
      "Processed 50 lines.\n",
      "Processed 51 lines.\n",
      "Processed 52 lines.\n",
      "Processed 53 lines.\n",
      "Processed 54 lines.\n",
      "Processed 55 lines.\n",
      "Processed 56 lines.\n",
      "Processed 57 lines.\n",
      "Processed 58 lines.\n",
      "Processed 59 lines.\n",
      "Processed 60 lines.\n",
      "Processed 61 lines.\n",
      "Processed 62 lines.\n",
      "Processed 63 lines.\n",
      "Processed 64 lines.\n",
      "Processed 65 lines.\n",
      "Processed 66 lines.\n",
      "Processed 67 lines.\n",
      "Processed 68 lines.\n",
      "Processed 69 lines.\n",
      "Processed 70 lines.\n",
      "Processed 71 lines.\n",
      "Processed 72 lines.\n",
      "Processed 73 lines.\n",
      "Processed 74 lines.\n",
      "Processed 75 lines.\n",
      "Processed 76 lines.\n",
      "Processed 77 lines.\n",
      "Processed 78 lines.\n",
      "Processed 79 lines.\n",
      "Processed 80 lines.\n",
      "Processed 81 lines.\n",
      "Processed 82 lines.\n",
      "Processed 83 lines.\n",
      "Processed 84 lines.\n",
      "Processed 85 lines.\n",
      "Processed 86 lines.\n",
      "Processed 87 lines.\n",
      "Processed 88 lines.\n",
      "Processed 89 lines.\n",
      "Processed 90 lines.\n",
      "Processed 91 lines.\n",
      "Processed 92 lines.\n",
      "Processed 93 lines.\n",
      "Processed 94 lines.\n",
      "Processed 95 lines.\n",
      "Processed 96 lines.\n",
      "Processed 97 lines.\n",
      "Processed 98 lines.\n",
      "Processed 99 lines.\n",
      "Processed 100 lines.\n",
      "Processed 101 lines.\n",
      "Processed 102 lines.\n",
      "Processed 103 lines.\n",
      "Processed 104 lines.\n",
      "Processed 105 lines.\n",
      "Processed 106 lines.\n",
      "Processed 107 lines.\n",
      "Processed 108 lines.\n",
      "Processed 109 lines.\n",
      "Processed 110 lines.\n",
      "Processed 111 lines.\n",
      "Processed 112 lines.\n",
      "Processed 113 lines.\n",
      "Processed 114 lines.\n",
      "Processed 115 lines.\n",
      "Processed 116 lines.\n",
      "Processed 117 lines.\n",
      "Processed 118 lines.\n",
      "Processed 119 lines.\n",
      "Processed 120 lines.\n",
      "Processed 121 lines.\n",
      "Processed 122 lines.\n",
      "Processed 123 lines.\n",
      "Processed 124 lines.\n",
      "Processed 125 lines.\n",
      "Processed 126 lines.\n",
      "Processed 127 lines.\n",
      "Processed 128 lines.\n",
      "Processed 129 lines.\n",
      "Processed 130 lines.\n",
      "Processed 131 lines.\n",
      "Processed 132 lines.\n",
      "Processed 133 lines.\n",
      "Processed 134 lines.\n",
      "Processed 135 lines.\n",
      "Processed 136 lines.\n",
      "Processed 137 lines.\n",
      "Processed 138 lines.\n",
      "Processed 139 lines.\n",
      "Processed 140 lines.\n",
      "Processed 141 lines.\n",
      "Processed 142 lines.\n",
      "Processed 143 lines.\n",
      "Processed 144 lines.\n",
      "Processed 145 lines.\n",
      "Processed 146 lines.\n",
      "Processed 147 lines.\n",
      "Processed 148 lines.\n",
      "Processed 149 lines.\n",
      "Processed 150 lines.\n",
      "Processed 151 lines.\n",
      "Processed 152 lines.\n",
      "Processed 153 lines.\n",
      "Processed 154 lines.\n",
      "Processed 155 lines.\n",
      "Processed 156 lines.\n",
      "Processed 157 lines.\n",
      "Processed 158 lines.\n",
      "Processed 159 lines.\n",
      "Processed 160 lines.\n",
      "Processed 161 lines.\n",
      "Processed 162 lines.\n",
      "Processed 163 lines.\n",
      "Processed 164 lines.\n",
      "Processed 165 lines.\n",
      "Processed 166 lines.\n",
      "Processed 167 lines.\n",
      "Processed 168 lines.\n",
      "Processed 169 lines.\n",
      "Processed 170 lines.\n",
      "Processed 171 lines.\n",
      "Processed 172 lines.\n",
      "Processed 173 lines.\n",
      "Processed 174 lines.\n",
      "Processed 175 lines.\n",
      "Processed 176 lines.\n",
      "Processed 177 lines.\n",
      "Processed 178 lines.\n",
      "Processed 179 lines.\n",
      "Processed 180 lines.\n",
      "Processed 181 lines.\n",
      "Processed 182 lines.\n",
      "Processed 183 lines.\n",
      "Processed 184 lines.\n",
      "Processed 185 lines.\n",
      "Processed 186 lines.\n",
      "Processed 187 lines.\n",
      "Processed 188 lines.\n",
      "Processed 189 lines.\n",
      "Processed 190 lines.\n",
      "Processed 191 lines.\n",
      "Processed 192 lines.\n",
      "Processed 193 lines.\n",
      "Processed 194 lines.\n",
      "Processed 195 lines.\n",
      "Processed 196 lines.\n",
      "Processed 197 lines.\n",
      "Processed 198 lines.\n",
      "Processed 199 lines.\n",
      "Processed 200 lines.\n",
      "Processed 201 lines.\n",
      "Processed 202 lines.\n",
      "Processed 203 lines.\n",
      "Processed 204 lines.\n",
      "Processed 205 lines.\n",
      "Processed 206 lines.\n",
      "Processed 207 lines.\n",
      "Processed 208 lines.\n",
      "Processed 209 lines.\n",
      "Processed 210 lines.\n",
      "Processed 211 lines.\n",
      "Processed 212 lines.\n",
      "Processed 213 lines.\n",
      "Processed 214 lines.\n",
      "Processed 215 lines.\n",
      "Processed 216 lines.\n",
      "Processed 217 lines.\n",
      "Processed 218 lines.\n",
      "Processed 219 lines.\n",
      "Processed 220 lines.\n",
      "Processed 221 lines.\n",
      "Processed 222 lines.\n",
      "Processed 223 lines.\n",
      "Processed 224 lines.\n",
      "Processed 225 lines.\n",
      "Processed 226 lines.\n",
      "Processed 227 lines.\n",
      "Processed 228 lines.\n",
      "Processed 229 lines.\n",
      "Processed 230 lines.\n",
      "Processed 231 lines.\n",
      "Processed 232 lines.\n",
      "Processed 233 lines.\n",
      "Processed 234 lines.\n",
      "Processed 235 lines.\n",
      "Processed 236 lines.\n",
      "Processed 237 lines.\n",
      "Processed 238 lines.\n",
      "Processed 239 lines.\n",
      "Processed 240 lines.\n",
      "Processed 241 lines.\n",
      "Processed 242 lines.\n",
      "Processed 243 lines.\n",
      "Processed 244 lines.\n",
      "Processed 245 lines.\n",
      "Processed 246 lines.\n",
      "Processed 247 lines.\n",
      "Processed 248 lines.\n",
      "Processed 249 lines.\n",
      "Processed 250 lines.\n",
      "Processed 251 lines.\n",
      "Processed 252 lines.\n",
      "Processed 253 lines.\n",
      "Processed 254 lines.\n",
      "Processed 255 lines.\n",
      "Processed 256 lines.\n",
      "Processed 257 lines.\n",
      "Processed 258 lines.\n",
      "Processed 259 lines.\n",
      "Processed 260 lines.\n",
      "Processed 261 lines.\n",
      "Processed 262 lines.\n",
      "Processed 263 lines.\n",
      "Processed 264 lines.\n",
      "Processed 265 lines.\n",
      "Processed 266 lines.\n",
      "Processed 267 lines.\n",
      "Processed 268 lines.\n",
      "Processed 269 lines.\n",
      "Processed 270 lines.\n",
      "Processed 271 lines.\n",
      "Processed 272 lines.\n",
      "Processed 273 lines.\n",
      "Processed 274 lines.\n",
      "Processed 275 lines.\n",
      "Processed 276 lines.\n",
      "Processed 277 lines.\n",
      "Processed 278 lines.\n",
      "Processed 279 lines.\n",
      "Processed 280 lines.\n",
      "Processed 281 lines.\n",
      "Processed 282 lines.\n",
      "Processed 283 lines.\n",
      "Processed 284 lines.\n",
      "Processed 285 lines.\n",
      "Processed 286 lines.\n",
      "Processed 287 lines.\n",
      "Processed 288 lines.\n",
      "Processed 289 lines.\n",
      "Processed 290 lines.\n",
      "Processed 291 lines.\n",
      "Processed 292 lines.\n",
      "Processed 293 lines.\n",
      "Processed 294 lines.\n",
      "Processed 295 lines.\n",
      "Processed 296 lines.\n",
      "Processed 297 lines.\n",
      "Processed 298 lines.\n",
      "Processed 299 lines.\n",
      "Processed 300 lines.\n",
      "Processed 301 lines.\n",
      "Processed 302 lines.\n",
      "Processed 303 lines.\n",
      "Processed 304 lines.\n",
      "Processed 305 lines.\n",
      "Processed 306 lines.\n",
      "Processed 307 lines.\n",
      "Processed 308 lines.\n",
      "Processed 309 lines.\n",
      "Processed 310 lines.\n",
      "Processed 311 lines.\n",
      "Processed 312 lines.\n",
      "Processed 313 lines.\n",
      "Processed 314 lines.\n",
      "Processed 315 lines.\n",
      "Processed 316 lines.\n",
      "Processed 317 lines.\n",
      "Processed 318 lines.\n",
      "Processed 319 lines.\n",
      "Processed 320 lines.\n",
      "Processed 321 lines.\n",
      "Processed 322 lines.\n",
      "Processed 323 lines.\n",
      "Processed 324 lines.\n",
      "Processed 325 lines.\n",
      "Processed 326 lines.\n",
      "Processed 327 lines.\n",
      "Processed 328 lines.\n",
      "Processed 329 lines.\n",
      "Processed 330 lines.\n",
      "Processed 331 lines.\n",
      "Processed 332 lines.\n",
      "Processed 333 lines.\n",
      "Processed 334 lines.\n",
      "Processed 335 lines.\n",
      "Processed 336 lines.\n",
      "Processed 337 lines.\n",
      "Processed 338 lines.\n",
      "Processed 339 lines.\n",
      "Processed 340 lines.\n",
      "Processed 341 lines.\n",
      "Processed 342 lines.\n",
      "Processed 343 lines.\n",
      "Processed 344 lines.\n",
      "Processed 345 lines.\n",
      "Processed 346 lines.\n",
      "Processed 347 lines.\n",
      "Processed 348 lines.\n",
      "Processed 349 lines.\n",
      "Processed 350 lines.\n",
      "Processed 351 lines.\n",
      "Processed 352 lines.\n",
      "Processed 353 lines.\n",
      "Processed 354 lines.\n",
      "Processed 355 lines.\n",
      "Processed 356 lines.\n",
      "Processed 357 lines.\n",
      "Processed 358 lines.\n",
      "Processed 359 lines.\n",
      "Processed 360 lines.\n",
      "Processed 361 lines.\n",
      "Processed 362 lines.\n",
      "Processed 363 lines.\n",
      "Processed 364 lines.\n",
      "Processed 365 lines.\n",
      "Processed 366 lines.\n",
      "Processed 367 lines.\n",
      "Processed 368 lines.\n",
      "Processed 369 lines.\n",
      "Processed 370 lines.\n",
      "Processed 371 lines.\n",
      "Processed 372 lines.\n",
      "Processed 373 lines.\n",
      "Processed 374 lines.\n",
      "Processed 375 lines.\n",
      "Processed 376 lines.\n",
      "Processed 377 lines.\n",
      "Processed 378 lines.\n",
      "Processed 379 lines.\n",
      "Processed 380 lines.\n",
      "Processed 381 lines.\n",
      "Processed 382 lines.\n",
      "Processed 383 lines.\n",
      "Processed 384 lines.\n",
      "Processed 385 lines.\n",
      "Processed 386 lines.\n",
      "Processed 387 lines.\n",
      "Processed 388 lines.\n",
      "Processed 389 lines.\n",
      "Processed 390 lines.\n",
      "Processed 391 lines.\n",
      "Processed 392 lines.\n",
      "Processed 393 lines.\n",
      "Processed 394 lines.\n",
      "Processed 395 lines.\n",
      "Processed 396 lines.\n",
      "Processed 397 lines.\n",
      "Processed 398 lines.\n",
      "Processed 399 lines.\n",
      "Processed 400 lines.\n",
      "Processed 401 lines.\n",
      "Processed 402 lines.\n",
      "Processed 403 lines.\n",
      "Processed 404 lines.\n",
      "Processed 405 lines.\n",
      "Processed 406 lines.\n",
      "Processed 407 lines.\n",
      "Processed 408 lines.\n",
      "Processed 409 lines.\n",
      "Processed 410 lines.\n",
      "Processed 411 lines.\n",
      "Processed 412 lines.\n",
      "Processed 413 lines.\n",
      "Processed 414 lines.\n",
      "Processed 415 lines.\n",
      "Processed 416 lines.\n",
      "Processed 417 lines.\n",
      "Processed 418 lines.\n",
      "Processed 419 lines.\n",
      "Processed 420 lines.\n",
      "Processed 421 lines.\n",
      "Processed 422 lines.\n",
      "Processed 423 lines.\n",
      "Processed 424 lines.\n",
      "Processed 425 lines.\n",
      "Processed 426 lines.\n",
      "Processed 427 lines.\n",
      "Processed 428 lines.\n",
      "Processed 429 lines.\n",
      "Processed 430 lines.\n",
      "Processed 431 lines.\n",
      "Processed 432 lines.\n",
      "Processed 433 lines.\n",
      "Processed 434 lines.\n",
      "Processed 435 lines.\n",
      "Processed 436 lines.\n",
      "Processed 437 lines.\n",
      "Processed 438 lines.\n",
      "Processed 439 lines.\n",
      "Processed 440 lines.\n",
      "Processed 441 lines.\n",
      "Processed 442 lines.\n",
      "Processed 443 lines.\n",
      "Processed 444 lines.\n",
      "Processed 445 lines.\n",
      "Processed 446 lines.\n",
      "Processed 447 lines.\n",
      "Processed 448 lines.\n",
      "Processed 449 lines.\n",
      "Processed 450 lines.\n",
      "Processed 451 lines.\n",
      "Processed 452 lines.\n",
      "Processed 453 lines.\n",
      "Processed 454 lines.\n",
      "Processed 455 lines.\n",
      "Processed 456 lines.\n",
      "Processed 457 lines.\n",
      "Processed 458 lines.\n",
      "Processed 459 lines.\n",
      "Processed 460 lines.\n",
      "Processed 461 lines.\n",
      "Processed 462 lines.\n",
      "Processed 463 lines.\n",
      "Processed 464 lines.\n",
      "Processed 465 lines.\n",
      "Processed 466 lines.\n",
      "Processed 467 lines.\n",
      "Processed 468 lines.\n",
      "Processed 469 lines.\n",
      "Processed 470 lines.\n",
      "Processed 471 lines.\n",
      "Processed 472 lines.\n",
      "Processed 473 lines.\n",
      "Processed 474 lines.\n",
      "Processed 475 lines.\n",
      "Processed 476 lines.\n",
      "Processed 477 lines.\n",
      "Processed 478 lines.\n",
      "Processed 479 lines.\n",
      "Processed 480 lines.\n",
      "Processed 481 lines.\n",
      "Processed 482 lines.\n",
      "Processed 483 lines.\n",
      "Processed 484 lines.\n",
      "Processed 485 lines.\n",
      "Processed 486 lines.\n",
      "Processed 487 lines.\n",
      "Processed 488 lines.\n",
      "Processed 489 lines.\n",
      "Processed 490 lines.\n",
      "Processed 491 lines.\n",
      "Processed 492 lines.\n",
      "Processed 493 lines.\n",
      "Processed 494 lines.\n",
      "Processed 495 lines.\n",
      "Processed 496 lines.\n",
      "Processed 497 lines.\n",
      "Processed 498 lines.\n",
      "Processed 499 lines.\n",
      "Processed 500 lines.\n",
      "Processed 501 lines.\n",
      "Processed 502 lines.\n",
      "Processed 503 lines.\n",
      "Processed 504 lines.\n",
      "Processed 505 lines.\n",
      "Processed 506 lines.\n",
      "Processed 507 lines.\n",
      "Processed 508 lines.\n",
      "Processed 509 lines.\n",
      "Processed 510 lines.\n",
      "Processed 511 lines.\n",
      "Processed 512 lines.\n",
      "Processed 513 lines.\n",
      "Processed 514 lines.\n",
      "Processed 515 lines.\n",
      "Processed 516 lines.\n",
      "Processed 517 lines.\n",
      "Processed 518 lines.\n",
      "Processed 519 lines.\n",
      "Processed 520 lines.\n",
      "Processed 521 lines.\n",
      "Processed 522 lines.\n",
      "Processed 523 lines.\n",
      "Processed 524 lines.\n",
      "Processed 525 lines.\n",
      "Processed 526 lines.\n",
      "Processed 527 lines.\n",
      "Processed 528 lines.\n",
      "Processed 529 lines.\n",
      "Processed 530 lines.\n",
      "Processed 531 lines.\n",
      "Processed 532 lines.\n",
      "Processed 533 lines.\n",
      "Processed 534 lines.\n",
      "Processed 535 lines.\n",
      "Processed 536 lines.\n",
      "Processed 537 lines.\n",
      "Processed 538 lines.\n",
      "Processed 539 lines.\n",
      "Processed 540 lines.\n",
      "Processed 541 lines.\n",
      "Processed 542 lines.\n",
      "Processed 543 lines.\n",
      "Processed 544 lines.\n",
      "Processed 545 lines.\n",
      "Processed 546 lines.\n",
      "Processed 547 lines.\n",
      "Processed 548 lines.\n",
      "Processed 549 lines.\n",
      "Processed 550 lines.\n",
      "Processed 551 lines.\n",
      "Processed 552 lines.\n",
      "Processed 553 lines.\n",
      "Processed 554 lines.\n",
      "Processed 555 lines.\n",
      "Processed 556 lines.\n",
      "Processed 557 lines.\n",
      "Processed 558 lines.\n",
      "Processed 559 lines.\n",
      "Processed 560 lines.\n",
      "Processed 561 lines.\n",
      "Processed 562 lines.\n",
      "Processed 563 lines.\n",
      "Processed 564 lines.\n",
      "Processed 565 lines.\n",
      "Processed 566 lines.\n",
      "Processed 567 lines.\n",
      "Processed 568 lines.\n",
      "Processed 569 lines.\n",
      "Processed 570 lines.\n",
      "Processed 571 lines.\n",
      "Processed 572 lines.\n",
      "Processed 573 lines.\n",
      "Processed 574 lines.\n",
      "Processed 575 lines.\n",
      "Processed 576 lines.\n",
      "Processed 577 lines.\n",
      "Processed 578 lines.\n",
      "Processed 579 lines.\n",
      "Processed 580 lines.\n",
      "Processed 581 lines.\n",
      "Processed 582 lines.\n",
      "Processed 583 lines.\n",
      "Processed 584 lines.\n",
      "Processed 585 lines.\n",
      "Processed 586 lines.\n",
      "Processed 587 lines.\n",
      "Processed 588 lines.\n",
      "Processed 589 lines.\n",
      "Processed 590 lines.\n",
      "Processed 591 lines.\n",
      "Processed 592 lines.\n",
      "Processed 593 lines.\n",
      "Processed 594 lines.\n",
      "Processed 595 lines.\n",
      "Processed 596 lines.\n",
      "Processed 597 lines.\n",
      "Processed 598 lines.\n",
      "Processed 599 lines.\n",
      "Processed 600 lines.\n",
      "Processed 601 lines.\n",
      "Processed 602 lines.\n",
      "Processed 603 lines.\n",
      "Processed 604 lines.\n",
      "Processed 605 lines.\n",
      "Processed 606 lines.\n",
      "Processed 607 lines.\n",
      "Processed 608 lines.\n",
      "Processed 609 lines.\n",
      "Processed 610 lines.\n",
      "Processed 611 lines.\n",
      "Processed 612 lines.\n",
      "Processed 613 lines.\n",
      "Processed 614 lines.\n",
      "Processed 615 lines.\n",
      "Processed 616 lines.\n",
      "Processed 617 lines.\n",
      "Processed 618 lines.\n",
      "Processed 619 lines.\n",
      "Processed 620 lines.\n",
      "Processed 621 lines.\n",
      "Processed 622 lines.\n",
      "Processed 623 lines.\n",
      "Processed 624 lines.\n",
      "Processed 625 lines.\n",
      "Processed 626 lines.\n",
      "Processed 627 lines.\n",
      "Processed 628 lines.\n",
      "Processed 629 lines.\n",
      "Processed 630 lines.\n",
      "Processed 631 lines.\n",
      "Processed 632 lines.\n",
      "Processed 633 lines.\n",
      "Processed 634 lines.\n",
      "Processed 635 lines.\n",
      "Processed 636 lines.\n",
      "Processed 637 lines.\n",
      "Processed 638 lines.\n",
      "Processed 639 lines.\n",
      "Processed 640 lines.\n",
      "Processed 641 lines.\n",
      "Processed 642 lines.\n",
      "Processed 643 lines.\n",
      "Processed 644 lines.\n",
      "Processed 645 lines.\n",
      "Processed 646 lines.\n",
      "Processed 647 lines.\n",
      "Processed 648 lines.\n",
      "Processed 649 lines.\n",
      "Processed 650 lines.\n",
      "Processed 651 lines.\n",
      "Processed 652 lines.\n",
      "Processed 653 lines.\n",
      "Processed 654 lines.\n",
      "Processed 655 lines.\n",
      "Processed 656 lines.\n",
      "Processed 657 lines.\n",
      "Processed 658 lines.\n",
      "Processed 659 lines.\n",
      "Processed 660 lines.\n",
      "Processed 661 lines.\n",
      "Processed 662 lines.\n",
      "Processed 663 lines.\n",
      "Processed 664 lines.\n",
      "Processed 665 lines.\n",
      "Processed 666 lines.\n",
      "Processed 667 lines.\n",
      "Processed 668 lines.\n",
      "Processed 669 lines.\n",
      "Processed 670 lines.\n",
      "Processed 671 lines.\n",
      "Processed 672 lines.\n",
      "Processed 673 lines.\n",
      "Processed 674 lines.\n",
      "Processed 675 lines.\n",
      "Processed 676 lines.\n",
      "Processed 677 lines.\n",
      "Processed 678 lines.\n",
      "Processed 679 lines.\n",
      "Processed 680 lines.\n",
      "Processed 681 lines.\n",
      "Processed 682 lines.\n",
      "Processed 683 lines.\n",
      "Processed 684 lines.\n",
      "Processed 685 lines.\n",
      "Processed 686 lines.\n",
      "Processed 687 lines.\n",
      "Processed 688 lines.\n",
      "Processed 689 lines.\n",
      "Processed 690 lines.\n",
      "Processed 691 lines.\n",
      "Processed 692 lines.\n",
      "Processed 693 lines.\n",
      "Processed 694 lines.\n",
      "Processed 695 lines.\n",
      "Processed 696 lines.\n",
      "Processed 697 lines.\n",
      "Processed 698 lines.\n",
      "Processed 699 lines.\n",
      "Processed 700 lines.\n",
      "Processed 701 lines.\n",
      "Processed 702 lines.\n",
      "Processed 703 lines.\n",
      "Processed 704 lines.\n",
      "Processed 705 lines.\n",
      "Processed 706 lines.\n",
      "Processed 707 lines.\n",
      "Processed 708 lines.\n",
      "Processed 709 lines.\n",
      "Processed 710 lines.\n",
      "Processed 711 lines.\n",
      "Processed 712 lines.\n",
      "Processed 713 lines.\n",
      "Processed 714 lines.\n",
      "Processed 715 lines.\n",
      "Processed 716 lines.\n",
      "Processed 717 lines.\n",
      "Processed 718 lines.\n",
      "Processed 719 lines.\n",
      "Processed 720 lines.\n",
      "Processed 721 lines.\n",
      "Processed 722 lines.\n",
      "Processed 723 lines.\n",
      "Processed 724 lines.\n",
      "Processed 725 lines.\n",
      "Processed 726 lines.\n",
      "Processed 727 lines.\n",
      "Processed 728 lines.\n",
      "Processed 729 lines.\n",
      "Processed 730 lines.\n",
      "Processed 731 lines.\n",
      "Processed 732 lines.\n",
      "Processed 733 lines.\n",
      "Processed 734 lines.\n",
      "Processed 735 lines.\n",
      "Processed 736 lines.\n",
      "Processed 737 lines.\n",
      "Processed 738 lines.\n",
      "Processed 739 lines.\n",
      "Processed 740 lines.\n",
      "Processed 741 lines.\n",
      "Processed 742 lines.\n",
      "Processed 743 lines.\n",
      "Processed 744 lines.\n",
      "Processed 745 lines.\n",
      "Processed 746 lines.\n",
      "Processed 747 lines.\n",
      "Processed 748 lines.\n",
      "Processed 749 lines.\n",
      "Processed 750 lines.\n",
      "Processed 751 lines.\n",
      "Processed 752 lines.\n",
      "Processed 753 lines.\n",
      "Processed 754 lines.\n",
      "Processed 755 lines.\n",
      "Processed 756 lines.\n",
      "Processed 757 lines.\n",
      "Processed 758 lines.\n",
      "Processed 759 lines.\n",
      "Processed 760 lines.\n",
      "Processed 761 lines.\n",
      "Processed 762 lines.\n",
      "Processed 763 lines.\n",
      "Processed 764 lines.\n",
      "Processed 765 lines.\n",
      "Processed 766 lines.\n",
      "Processed 767 lines.\n",
      "Processed 768 lines.\n",
      "Processed 769 lines.\n",
      "Processed 770 lines.\n",
      "Processed 771 lines.\n",
      "Processed 772 lines.\n",
      "Processed 773 lines.\n",
      "Processed 774 lines.\n",
      "Processed 775 lines.\n",
      "Processed 776 lines.\n",
      "Processed 777 lines.\n",
      "Processed 778 lines.\n",
      "Processed 779 lines.\n",
      "Processed 780 lines.\n",
      "Processed 781 lines.\n",
      "Processed 782 lines.\n",
      "Processed 783 lines.\n",
      "Processed 784 lines.\n",
      "Processed 785 lines.\n",
      "Processed 786 lines.\n",
      "Processed 787 lines.\n",
      "Processed 788 lines.\n",
      "Processed 789 lines.\n",
      "Processed 790 lines.\n",
      "Processed 791 lines.\n",
      "Processed 792 lines.\n",
      "Processed 793 lines.\n",
      "Processed 794 lines.\n",
      "Processed 795 lines.\n",
      "Processed 796 lines.\n",
      "Processed 797 lines.\n",
      "Processed 798 lines.\n",
      "Processed 799 lines.\n",
      "Processed 800 lines.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "# Download the Hindi models for stanza\n",
    "stanza.download('hi')\n",
    "\n",
    "# Initialize the Hindi pipeline without the MWT processor\n",
    "nlp = stanza.Pipeline(lang='hi', processors='tokenize,pos,lemma')\n",
    "\n",
    "# Initialize a counter\n",
    "counter = 0\n",
    "\n",
    "# Define a function to extract lemmas\n",
    "def extract_lemmas(text):\n",
    "    # # Join the tokens into a string\n",
    "    # text = ' '.join(text)\n",
    "    global counter\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    # Extract lemmas and join them into a string\n",
    "    lemmas = ' '.join(word.lemma for sent in doc.sentences for word in sent.words)\n",
    "    # Increment the counter\n",
    "    counter += 1\n",
    "    # Print the counter\n",
    "    print(f\"Processed {counter} lines.\")\n",
    "    return lemmas\n",
    "\n",
    "# Apply the function to the 'lyrics_devanagari' column\n",
    "data['lyrics_lemmatized'] = data['Devanagari_spell_check'].apply(extract_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Devanagari_spell_check  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         का\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम् रही है आली\\tधु\\tमैन् पी कर मदद की प्याली\\tयून् चाल चलने मतवाली\\tयून् चाल चलने मतवाली\\tका\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम् रही है आली\\tमतवाली\\tमतवाली\\tमतवाली\\tधु\\tमतवाली\\tमतवाली\\tमतवाली\\tमैन् चाल चलने मतवाला का\\tमैन् चाल चलने मतवाला धु\\tदरा दर्द दर् दर्द दर् दर्द द का\\tदरा दर्द दर् दर्द दर् दर्द द\\tमोरे अन्ना मेन आये आलीआली\\tमैन् चाल चलने मतवाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tअम्बूवा की दालीदाली\\tझूम् रही है आली\\tझूम् रही है आली\\tदो\\tमतवाली\\tमतवाली\\tमतवाली\\tमतवाली\\tमतवाली\\tमतवाली\\tमैन् चाल चलने मतवाली\\tमैन् चाल चलने मतवाली\\tमोरे अन्ना मेन आये आलीआली\\tमैन् चाल चलने मतवाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tझूम् रही है आली\\tअम्बूवा की दाली\\tअम्बूवा की दालीदाली\\tझूम् रही है आली   \n",
      "1  को\\tहे हो धोखे महोबा घात्\\tहे हो धोखे महोबा घात्\\tस\\tधोबिया रे धोबिया\\tकहान् तुम्हारो\\tयौनन् कौनन्\\tकहान् तुम्हारे घात्\\tहे हो कहानी तुम्हारे घात्\\tहे हो कहानी तुम्हारे घात्\\tको\\tमिरज़ापुर् मेन्\\tऔनन् कौनन्\\tकभी हमारे घात्\\tहे हो कभी हमारे घात्\\tहे हो कभी हमारे घात्\\tहे हो कभी हमारे घात्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tधोये महोबा घात्\\tहे हो धोखे महोबा घात्\\tचान्दी की नदिया मेन धोनी की अन्गिया\\tचान्दी की नदिया मेन धोनी की अन्गिया\\tधोये रे धोखे रे मस्सा धोतिया\\tधोये रे धोखे रे मस्सा धोतिया\\tचम्चम् सकेगी इन्डिया पहने के\\tचम्चम् सकेगी इन्डिया पहने के\\tबरसेन्गे सुन्दरी पे तारे गगन के\\tबरसेन्गे सुन्दरी पे तारे गगन के\\tको\\tधोये महोबा घात्\\tहे हो धोखे महोबा घात्\\tहे हो धोखे महोबा घात्\\tहे हो धोखे महोबा घात्\\tसजो तुम्हारो\\tप्यारो जोबन्\\tसजो तुम्हारे घात्\\tहे हो जो तुम्हारे घात्\\tहे हो जो तुम्हारे घात्\\tहे हो जो तुम्हारे घात्\\tस\\tहमरा तुम्हारा बन्धन रे पैन्जन्\\tहमरा तुम्हारा बन्धन रे पैन्जन्\\tचलेन् निकाले थाथ्\\tहे हो चले निकाले थाथ्\\tहे हो चले निकाले थाथ्\\tको\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tधोये महोबा घात्\\tहे हो धोखे महोबा घात्\\tस\\tहो मोरे फोबिया की नगदी पुरानी\\tहो मोरे फोबिया की नगदी पुरानी\\tपगदी पुरानी क्यू धोखे महारानी\\tपगदी पुरानी क्यू धोखे महारानी\\tधोबिया की गोदी मेन रानी समिति गयी\\tधोबिया की गोदी मेन रानी समिति गयी\\tको\\tधोये महोबा घात्\\tहे हो धोखे महोबा घात्\\tहे हो धोखे महोबा घात्\\tहे हो धोखे महोबा घात्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tहैयो राम्\\tधोये महोबा घात   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                        अन्ना मेन आये आली मेन चाल चलने मतवाली\\tअन्गना मेन आये आली मेन चाल चलने मतवाली\\tअन्गना मेन आये आ\\tऐ सुनती हो सुनसान सन् उन् मुझसे कहा रहे है् हानि ये कैसे गीत गा रही है क्यू जी ये तो दे अच्छे गीत है् अच्छे गीत है् रामकिशन के प्रेम के गीत है् रामकिशन के प्रेम के गीत है् सुना तो सुनेगा बैरियर बैथिये आइये बैरियर यह् उह् यह् उह् यह् अहम ह ह ह ह ह सुनाये राधिका अपनी सहेली से कहा रही है के जब श्री क्रिश्न्\\tमोरे अन्ना मेन आये आली मेन चाल चलने मतवाला अन्ना मेन आये आ\\tजब् आर्चर हम्रा परदे हम हन्शन्स् उनसे बचे\\tजब् आर्चर हम्रा परदे हम हन्शन्स् उनसे बचे\\tचोली पे नजरिया आ जाये चोली पे नजरिया जाये मोरी चुनरी लिप्त मोटे जाये हानि हान् चुनरी लिप्त मोसे\\tबस् बस रहने दो तुम मिथिला की बहूबेतियोन् का सत्यानन्द करके ढोंगी चोली पे उफ़्\\tजी भरा सुना तो लीजिये और क्या अब भी कुछ बाकी है हुम्\\tवो और बेन मोरे पैमाने पदेन कहानी मानो बात हमारी\\tवो और बेन मोरे पैमाने पदेन कहानी मानो बात हमारी\\tमैन् आहत भरने मुख फेरे कहून्\\tमैन् आहत भरने मुख फेरे कहून्\\tनहीन् मानूंगी बात तैयारी हानि नहीं मानूंगी बात तैयारी नहीं मानूंगी बात तैयारी तेहारी नहीं मानूंगी बात लोहारी हानि नहीं मानूंगी बात तैयारी तुम्हारी   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                       उ\\tप्रेम् नगर' मेन बनाऊंगा घर) मैन सके घर) सन्सार्\\tप्रेम् नगर' मेन बनाऊंगा घर) मैन सके घर) सन्सार्\\tप्रेम् का आर्गन प्रेम की छत और प्रेम के होन्ग द्वार्\\tप्रेम् का आर्गन प्रेम की छत और प्रेम के होन्ग द्वार्\\tप्रेम् नगर' मेन बनाऊंगा घर) मैन सके घर) सन्सार्\\tप्रेम् नगर' मेन बनाऊंगा घर) मैन सके घर) सन्सार्\\tस्\\tप्रेम् सखा हो प्रेम पदौसी\\tप्रेम् मेन सुख का सारा प्रेम मेन दुर्ग का सार्\\tप्रेम् सखा हो प्रेम पदौसी\\tप्रेम् मेन दुर्ग का सारा प्रेम मेन सुख का सार्\\tप्रेम् के सन् बतायेंगे जीवन्\\tप्रेम् के सन् बतायेंगे जीवन्\\tप्रेम् ही प्रानाधार्\\tप्रेम् के सन् बतायेंगे जीवन) प्रेम ही प्रानाधार्\\tप्रेम् सखा हो प्रेम पदौसी\\tप्रेम् मेन सुख का सारा प्रेम मेन दुर्ग का सार्\\tप्रेम् के सन् बतायेंगे जीवन्\\tप्रेम् के सन् बतायेंगे जीवन्\\tप्रेम् ही प्रानाधार्\\tउ\\tप्रेम् सुधा से स्नान करून्गी\\tप्रेम् से होगा श्रिन्गार् प्रेम से होगा श्रिन्गार्\\tप्रेम् से होगा श्रिन्गार् प्रेम से होगा श्रिन्गार्\\tस्\\tप्रेम् ही कर्म है प्रेम ही धर्म् है\\tप्रेम् ही सन्त) विचार' प्रेम ही सन्त) विचार्\\tप्रेम् ही सन्त) विचार' प्रेम ही सन्त) विचार्\\tउ\\tप्रेम् नगर' मेन बनाऊंगा घर) मैन सके घर) संसार   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                      कोई प्रीति की रीति बता दो हमें कोई मन का मीता मिला दो हमें कोई ऐसा गीत सुना दो हमें खिले जाये दिल से दिल की कली\\t कोई प्रीति की रीति बता दो हमें कोई मन का मीता मिला दो हमें कोई ऐसा गीत सुना दो हमें खिले जाये दिल से दिल की कली\\tबनवासी मीता कहानी जाने परदेसी प्रीति कहानी जाने हम ऐसा गीत कहानी जाने\\tबनवासी मीता कहानी जाने परदेसी प्रीति कहानी जाने हम ऐसा गीत कहानी जाने\\tखिल् जाये दिल से दिल की कली\\tखिल् जाये दिल से दिल की कली\\tयहान् दिल की की कही न खिली\\tयहान् दिल की की कही न खिली\\tये सब शहरों के उन्दे है् ये हिर्सोहवस् के उन्दे है् हम तो सैलानी बन्द है् हम प्रीति की रीति कहानी जाने\\tये सब शहरों के उन्दे है् ये हिर्सोहवस् के उन्दे है् हम तो सैलानी बन्द है् हम प्रीति की रीति कहानी जाने\\tदिल् जन्म ही मैन बदलता है महान् होन्थोन् पे गीत मिलता है\\tदिल् जन्म ही मैन बदलता है महान् होन्थोन् पे गीत मिलता है\\tयहान् प्रेम का सागर चलता है\\tयहान् प्रेम का सागर चलता है\\tहमेन् प्रीति की रीति बता दे कोई हमें ऐसा गीत सुना दे कोई\\tहमेन् प्रीति की रीति बता दे कोई हमें ऐसा गीत सुना दे कोई\\tखिल् जाये दिल से दिल की कली\\tखिल् जाये दिल से दिल की कली\\tयहान् दिल की की तो कभी ना खिली\\tयहान् दिल की की तो कभी ना मिली   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  lyrics_lemmatized  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       का अम्बूवा का दालीदाली झूम् रह है आली झूम् रह है आली धु मैन् पी कर मदद का प्याली यून् चाल चल मतवाली यून् चाल चल मतवाली का अम्बूवा का दालीदाली झूम् रह है आली झूम् रह है आली मतवाली मतवाली मतवाली धु मतवाली मतवाली मतवाली मैन् चाल चल मतवाला का मैन् चाल चल मतवाला धु दरा दर्द दर् दर्द दर् दर्द द का दरा दर्द दर् दर्द दर् दर्द द मोरे अन्ना मेन आ आलीआली मैन् चाल चल मतवाली झूम् रह है आली अम्बूवा का दाली झूम् रह है आली अम्बूवा का दाली अम्बूवा का दालीदाली झूम् रह है आली झूम् रह है आली दो मतवाली मतवाली मतवाली मतवाली मतवाली मतवाली मैन् चाल चल मतवाली मैन् चाल चल मतवाली मोरे अन्ना मेन आ आलीआली मैन् चाल चल मतवाली झूम् रह है आली अम्बूवा का दाली झूम् रह है आली अम्बूवा का दाली अम्बूवा का दालीदाली झूम् रह है आली   \n",
      "1  को हा हो धोखा महोबा घात् हे हो धोखा महोबा घात् स धोबिया रे धोबिया कहान् तुम्हारो यौनन् कौनन् कहान् तुम घात् हा हो कहानी तुम घात् हा हो कहानी तुम घात् को मिरज़ापुर् मेन् औनन् कौनन् कभी हम घात् हा हो कभी हम घात् हा हो कभी हम घात् हा हो कभी हम घात् हैयो राम् हैयो राम् हैयो राम् हैयो राम् हैयो राम् हैयो राम् धोये महोबा घात् हा हो धोखा महोबा घात् चान्दी का नदिया मेन धोनी का अन्गिया चान्दी का नदिया मेन धोनी का अन्गिया धोये रे धोखा रे मस्सा धोतिया धोये रे धोखा रे मस्सा धोतिया चम्चम् सक इन्डिया पहन का चम्चम् सक इन्डिया पहन का बरसेन्गे सुन्दरी पे तारा गगन का बरसेन्गे सुन्दरी पे तारा गगन का को धो महोबा घात् हे हो धोखा महोबा घात् हे हो धोखा महोबा घात् हे हो धोखा महोबा घात् सजो तुम्हारो प्यारो जोबन् सजो तुम घात् हा हो जो तुम घात् हा हो जो तुम घात् हा हो जो तुम घात् स हमरा तुम्हारा बन्धन रे पैन्जन् हमरा तुम्हारा बन्धन रे पैन्जन् चलेन् निकाल थाथ् हे हो चल निकाल थाथ् हा हो चल निकाल थाथ् को हैयो राम् हैयो राम् हैयो राम् हैयो राम् हैयो राम् हैयो राम् धोये महोबा घात् हे हो धोखा महोबा घात् स हो मोरे फोबिया का नगदी पुराना हो मोरे फोबिया का नगदी पुराना पगदी पुराना क्यू धोखा महारानी पगदी पुराना क्यू धोखा महारानी धोबिया का गोदी मेन रानी समिति जा धोबिया का गोदी मेन रानी समिति जा को धो महोबा घात् हे हो धोखा महोबा घात् हे हो धोखा महोबा घात् हा हो धोखा महोबा घात् हैयो राम् हैयो राम् हैयो राम् हैयो राम् हैयो राम् हैयो राम् धो महोबा घात   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                      अन्ना मेन आ आली मेन चाल चल मतवाली अन्गना मेन आ आली मेन चाल चल मतवाली अन्गना मेन आ आ ऐ सुन हो सुनसान सन् वह मैं कह रह है् हानि यह कैसे गीत गा रह है क्यू जी यह तो दे अच्छा गीत है् अच्छा गीत है् रामकिशन का प्रेम का गीत है् रामकिशन का प्रेम का गीत है् सुन तो सुन बैरियर बैथिये आ बैरियर यह् उह् यह् उह् यह् अहम ह ह ह ह ह सुना राधिका अपना सहेली से कह रह है का जब श्री क्रिश्न् मोरे अन्ना मेन आ आली मेन चाल चल मतवाला अन्ना मेन आ आ जब् आर्चर हम्रा परदा हम हन्शन वह बच जब् आर्चर हम्रा परदा हम हन्शन वह बच चोली पे नजरिया आ जा चोली पे नजरिया जा मोरी चुनरा लिप्त मोटा जा हानि हान् चुनरा लिप्त मोसे बस् बस रह दो तुम मिथिला का बहूबेतियोन् का सत्यानन्द कर ढो चोली पे उफ़् जी भर सुन तो लीज और क्या अब भी कुछ बाकी है हुम् वह और बेन मोरे पैमाना पदेन कहानी मानो बात हम वह और बेन मोरे पैमाना पदेन कहानी मानो बात हम मैन् आहत भर मुख फेर कहून् मैन् आहत भर मुख फेर कहून् नहीन् मान बात तैयारी हानि नहीं मान बात तैयारी नहीं मान बात तैयारी तेहारी नहीं मान बात लोहारी हानि नहीं मान बात तैयारी तुम्हारी   \n",
      "3                                                                                                                                                                                                                                                                                                                                उ प्रेम् नगर ' मेन बनाऊंगा घर ) मैन सक घर ) सन्सार् प्रेम् नगर ' मेन बनाऊंगा घर ) मैन सक घर ) सन्सार् प्रेम् का आर्गन प्रेम का छत और प्रेम का होन्ग द्वार् प्रेम् का आर्गन प्रेम का छत और प्रेम का होन्ग द्वार् प्रेम् नगर ' मेन बना घर ) मैन सक घर ) सन्सार् प्रेम् नगर ' मेन बना घर ) मैन सक घर ) सन्सार् स् प्रेम् सखा हो प्रेम पदौसी प्रेम् मेन सुख का सारा प्रेम मेन दुर्ग का सार् प्रेम् सखा हो प्रेम पदौसी प्रेम् मेन दुर्ग का सारा प्रेम मेन सुख का सार् प्रेम् का सन् बता जीवन् प्रेम् का सन् बता जीवन् प्रेम् ही प्रानाधार् प्रेम् का सन् बता जीवन ) प्रेम ही प्रानाधार् प्रेम् सखा हो प्रेम पदौसी प्रेम् मेन सुख का सारा प्रेम मेन दुर्ग का सार् प्रेम् का सन् बता जीवन् प्रेम् का सन् बता जीवन् प्रेम् ही प्रानाधार् ( प्रेम् सुधा से स्नान करून्गी प्रेम् से हो श्रिन्गार् प्रेम से हो श्रिन्गार् प्रेम् से हो श्रिन्गार् प्रेम से हो श्रिन्गार् स् प्रेम् ही कर्म है प्रेम ही धर्म् है प्रेम् ही सन्त ) विचार ' प्रेम ही सन्त ) विचार् प्रेम् ही सन्त ) विचार ' प्रेम ही सन्त ) विचार् उ प्रेम् नगर ' मेन बना घर ) मैन सक घर ) संसार   \n",
      "4                                                                                                                                                                                                                                                                                                                                        कोई प्रीति का रीति बता दो हम कोई मन का मीता मिल दो हम कोई ऐसा गीत सुन दो हम खिल जा दिल से दिल का कली कोई प्रीति का रीति बता दो हम कोई मन का मीता मिल दो हम कोई ऐसा गीत सुन दो हम खिल जा दिल से दिल का कली बनवासी मीता कहानी जा परदेसी प्रीति कहानी जा हम ऐसा गीत कहानी जा बनवासी मीता कहानी जा परदेसी प्रीति कहानी जा हम ऐसा गीत कहानी जा खिल् जा दिल से दिल का कली खिल् जा दिल से दिल का कली यहान् दिल का का कह न खिल यहान् दिल का का कह न खिल यह सब शहर का उन्दा है् यह हिर्सोहवस् का उन्दा है् हम तो सैलानी बंद है् हम प्रीति का रीति कहानी जा यह सब शहर का उन्दा है् यह हिर्सोहवस् का उन्दा है् हम तो सैलानी बंद है् हम प्रीति का रीति कहानी जा दिल् जन्म ही मैन बदल है महान् होन्थोन् पे गीत मिल है दिल् जन्म ही मैन बदल है महान् होन्थोन् पे गीत मिल है यहान् प्रेम का सागर चल है यहान् प्रेम का सागर चल है हमेन् प्रीति का रीति बता दे कोई हम ऐसा गीत सुन दे कोई हम प्रीति का रीति बता दे कोई हम ऐसा गीत सुन दे कोई खिल् जा दिल से दिल का कली खिल् जा दिल से दिल का कली यहान् दिल का का तो कभी ना खिल यहान् दिल का का तो कभी ना मिल   \n",
      "\n",
      "   lemmatization_change  \n",
      "0              0.120548  \n",
      "1              0.138252  \n",
      "2              0.130028  \n",
      "3              0.107900  \n",
      "4              0.121996  \n"
     ]
    }
   ],
   "source": [
    "# Set the maximum column width to None to display the full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import Levenshtein as lev\n",
    "\n",
    "# Define a function to calculate the Levenshtein distance\n",
    "def calculate_change(original, lemmatized):\n",
    "    # Calculate the Levenshtein distance\n",
    "    distance = lev.distance(original, lemmatized)\n",
    "    # Normalize the distance by the length of the original text\n",
    "    normalized_distance = distance / max(len(original), 1)\n",
    "    return normalized_distance\n",
    "\n",
    "# Apply the function to the 'lyrics_devanagari' and 'lyrics_lemmatized' columns\n",
    "data['lemmatization_change'] = data.apply(lambda row: calculate_change(row['Devanagari_spell_check'], row['lyrics_lemmatized']), axis=1)\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(data[['Devanagari_spell_check', 'lyrics_lemmatized', 'lemmatization_change']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Loading:\n",
    "\n",
    "We'll use pandas to read the csv file contaning the national anthem for each country and it's corresponding country code. The anthems were extracted from wikipedia and many of them contain words that use non UTF-8 characters (generaly names of places and such), so we'll read the file with the _latin1_ encoding.\n",
    "\n",
    "Then we'll extract the __Anthem__ column into a list of texts for our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('datasets/anthems.csv', encoding='utf-8')\n",
    "# data.columns = map(str.lower, data.columns)\n",
    "\n",
    "# continents = ['Europe', 'South_America', 'North_America']\n",
    "# data = data.loc[data['continent'].isin(continents)]\n",
    "# data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = data['anthem'].tolist()\n",
    "# corpus[18][0:447]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Processing\n",
    "\n",
    "### 1. Stop Words and Stemming\n",
    "We will do a data engineering routine with our anthems dataset so later we can make a good statistical model. In order to do so, we'll remove all words that don't contribute to the semantic meaning of the text (words that are not within the english alphabet) and keep all of the remaining words in the simplest format possible, so we can apply a function that gives weights to each word without generating any bias or outliers. To do that there are many techniques to clean up our corpus, among them we will remove the most common words ([stop words](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/)) and apply [stemming](https://www.researchgate.net/figure/Stemming-process-Algorithms-of-stemming-methods-are-divided-into-three-parts-mixed_fig2_324685008), a technique that reduces a word to it's root.\n",
    "\n",
    "The methods that apply stemming and stop words removal are listed bellow. We will also define a method that removes any words with less than 2 letters or more than 21 letters to clean our corpus even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # removes a list of words (ie. stopwords) from a tokenized list.\n",
    "# def removeWords(listOfTokens, listOfWords):\n",
    "#     return [token for token in listOfTokens if token not in listOfWords]\n",
    "\n",
    "# # applies stemming to a list of tokenized words\n",
    "# def applyStemming(listOfTokens, stemmer):\n",
    "#     return [stemmer.stem(token) for token in listOfTokens]\n",
    "\n",
    "# # removes any words composed of less than 2 or more than 21 letters\n",
    "# def twoLetters(listOfTokens):\n",
    "#     twoLetterWord = []\n",
    "#     for token in listOfTokens:\n",
    "#         if len(token) <= 2 or len(token) >= 21:\n",
    "#             twoLetterWord.append(token)\n",
    "#     return twoLetterWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The main corpus processing function.\n",
    "\n",
    "A section back, at the exploration of our dataset, we noticed some words containg weird characters that should be removed. By using RegEx our main processing function will remove unknown ASCII symbols, especial chars, numbers, e-mails, URLs, etc (It's a bit of a overkill, I know). It also uses the auxiliary funcitions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processCorpus(corpus, language):   \n",
    "#     stopwords = nltk.corpus.stopwords.words(language)\n",
    "#     param_stemmer = SnowballStemmer(language)\n",
    "#     countries_list = [line.rstrip('\\n') for line in open('lists/countries.txt')] # Load .txt file line by line\n",
    "#     nationalities_list = [line.rstrip('\\n') for line in open('lists/nationalities.txt')] # Load .txt file line by line\n",
    "#     other_words = [line.rstrip('\\n') for line in open('lists/stopwords_scrapmaker.txt')] # Load .txt file line by line\n",
    "    \n",
    "#     for document in corpus:\n",
    "#         index = corpus.index(document)\n",
    "#         corpus[index] = corpus[index].replace(u'\\ufffd', '8')   # Replaces the ASCII '�' symbol with '8'\n",
    "#         corpus[index] = corpus[index].replace(',', '')          # Removes commas\n",
    "#         corpus[index] = corpus[index].rstrip('\\n')              # Removes line breaks\n",
    "#         corpus[index] = corpus[index].casefold()                # Makes all letters lowercase\n",
    "        \n",
    "#         corpus[index] = re.sub('\\W_',' ', corpus[index])        # removes specials characters and leaves only words\n",
    "#         corpus[index] = re.sub(\"\\S*\\d\\S*\",\" \", corpus[index])   # removes numbers and words concatenated with numbers IE h4ck3r. Removes road names such as BR-381.\n",
    "#         corpus[index] = re.sub(\"\\S*@\\S*\\s?\",\" \", corpus[index]) # removes emails and mentions (words with @)\n",
    "#         corpus[index] = re.sub(r'http\\S+', '', corpus[index])   # removes URLs with http\n",
    "#         corpus[index] = re.sub(r'www\\S+', '', corpus[index])    # removes URLs with www\n",
    "\n",
    "#         listOfTokens = word_tokenize(corpus[index])\n",
    "#         twoLetterWord = twoLetters(listOfTokens)\n",
    "\n",
    "#         listOfTokens = removeWords(listOfTokens, stopwords)\n",
    "#         listOfTokens = removeWords(listOfTokens, twoLetterWord)\n",
    "#         listOfTokens = removeWords(listOfTokens, countries_list)\n",
    "#         listOfTokens = removeWords(listOfTokens, nationalities_list)\n",
    "#         listOfTokens = removeWords(listOfTokens, other_words)\n",
    "        \n",
    "#         listOfTokens = applyStemming(listOfTokens, param_stemmer)\n",
    "#         listOfTokens = removeWords(listOfTokens, other_words)\n",
    "\n",
    "#         corpus[index]   = \" \".join(listOfTokens)\n",
    "#         corpus[index] = unidecode(corpus[index])\n",
    "\n",
    "#     return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language = 'english'\n",
    "# corpus = processCorpus(corpus, language)\n",
    "# corpus[18][0:460]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Weighting of Words\n",
    "\n",
    "Now we will apply the [TF-IDF](https://jmotif.github.io/sax-vsm_site/morea/algorithm/TFIDF.html) function, short for term frequency inverse document frequency, which is a numerical statistic that's intended to reflect how important a word is to a document in a corpus by giving each word in a document a score that ranges from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# final_df = tf_idf\n",
    "\n",
    "# print(\"{} rows\".format(final_df.shape[0]))\n",
    "# final_df.T.nlargest(5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 rows\n",
      "          0         1         2    3    4    5         6         7    \\\n",
      "मतव  0.682286  0.000000  0.264788  0.0  0.0  0.0  0.000000  0.000000   \n",
      "आल   0.605069  0.000000  0.313094  0.0  0.0  0.0  0.000000  0.000000   \n",
      "अम   0.282806  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
      "दर   0.217668  0.078083  0.000000  0.0  0.0  0.0  0.116900  0.138207   \n",
      "रह   0.147901  0.000000  0.139149  0.0  0.0  0.0  0.086652  0.000000   \n",
      "\n",
      "          8    9    ...       790       791  792       793       794  795  \\\n",
      "मतव  0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
      "आल   0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
      "अम   0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
      "दर   0.418796  0.0  ...  0.000000  0.000000  0.0  0.000000  0.393158  0.0   \n",
      "रह   0.000000  0.0  ...  0.112771  0.103315  0.0  0.321609  0.058286  0.0   \n",
      "\n",
      "     796     797  798       799  \n",
      "मतव  0.0  0.0000  0.0  0.000000  \n",
      "आल   0.0  0.0000  0.0  0.000000  \n",
      "अम   0.0  0.0000  0.0  0.000000  \n",
      "दर   0.0  0.0268  0.0  0.124435  \n",
      "रह   0.0  0.0000  0.0  0.000000  \n",
      "\n",
      "[5 rows x 800 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Perform TF-IDF on the 'lyrics_lemmatized' column\n",
    "X = vectorizer.fit_transform(data['lyrics_lemmatized'])\n",
    "\n",
    "# Check if the vectorizer was fitted correctly\n",
    "if not hasattr(vectorizer, 'vocabulary_'):\n",
    "    print(\"The vectorizer was not fitted correctly.\")\n",
    "else:\n",
    "    # Convert the result to a DataFrame\n",
    "    tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Assign the DataFrame to final_df\n",
    "    final_df = tf_idf\n",
    "\n",
    "    # Print the number of rows in the DataFrame\n",
    "    print(\"{} rows\".format(final_df.shape[0]))\n",
    "\n",
    "    # Print the 5 largest values in the first row\n",
    "    print(final_df.T.nlargest(5, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>790</th>\n",
       "      <th>791</th>\n",
       "      <th>792</th>\n",
       "      <th>793</th>\n",
       "      <th>794</th>\n",
       "      <th>795</th>\n",
       "      <th>796</th>\n",
       "      <th>797</th>\n",
       "      <th>798</th>\n",
       "      <th>799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>मतव</th>\n",
       "      <td>0.682286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>आल</th>\n",
       "      <td>0.605069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>अम</th>\n",
       "      <td>0.282806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>दर</th>\n",
       "      <td>0.217668</td>\n",
       "      <td>0.078083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116900</td>\n",
       "      <td>0.138207</td>\n",
       "      <td>0.418796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>रह</th>\n",
       "      <td>0.147901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112771</td>\n",
       "      <td>0.103315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321609</td>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3    4    5         6         7    \\\n",
       "मतव  0.682286  0.000000  0.264788  0.0  0.0  0.0  0.000000  0.000000   \n",
       "आल   0.605069  0.000000  0.313094  0.0  0.0  0.0  0.000000  0.000000   \n",
       "अम   0.282806  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
       "दर   0.217668  0.078083  0.000000  0.0  0.0  0.0  0.116900  0.138207   \n",
       "रह   0.147901  0.000000  0.139149  0.0  0.0  0.0  0.086652  0.000000   \n",
       "\n",
       "          8    9    ...       790       791  792       793       794  795  \\\n",
       "मतव  0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "आल   0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "अम   0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "दर   0.418796  0.0  ...  0.000000  0.000000  0.0  0.000000  0.393158  0.0   \n",
       "रह   0.000000  0.0  ...  0.112771  0.103315  0.0  0.321609  0.058286  0.0   \n",
       "\n",
       "     796     797  798       799  \n",
       "मतव  0.0  0.0000  0.0  0.000000  \n",
       "आल   0.0  0.0000  0.0  0.000000  \n",
       "अम   0.0  0.0000  0.0  0.000000  \n",
       "दर   0.0  0.0268  0.0  0.124435  \n",
       "रह   0.0  0.0000  0.0  0.000000  \n",
       "\n",
       "[5 rows x 800 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 words with highest weight on document 0:\n",
    "final_df.T.nlargest(5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "##### Function that runs the K-Means algorithm *max_k* times and returns a dictionary of each k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KMeans(max_k, data):\n",
    "    max_k += 1\n",
    "    kmeans_results = dict()\n",
    "    for k in range(2 , max_k):\n",
    "        kmeans = cluster.KMeans(n_clusters = k\n",
    "                               , init = 'k-means++'\n",
    "                               , n_init = 10\n",
    "                               , tol = 0.0001\n",
    "                               , n_jobs = -1\n",
    "                               , random_state = 1\n",
    "                               , algorithm = 'full')\n",
    "\n",
    "        kmeans_results.update( {k : kmeans.fit(data)} )\n",
    "        \n",
    "    return kmeans_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Score\n",
    "\n",
    "The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAvg(avg_dict):\n",
    "    for avg in sorted(avg_dict.keys(), reverse=True):\n",
    "        print(\"Avg: {}\\tK:{}\".format(avg.round(4), avg_dict[avg]))\n",
    "        \n",
    "def plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg):\n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    fig.set_size_inches(8, 6)\n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    ax1.set_ylim([0, len(df) + (n_clusters + 1) * 10])\n",
    "    \n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\") # The vertical line for average silhouette score of all the values\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.title((\"Silhouette analysis for K = %d\" % n_clusters), fontsize=10, fontweight='bold')\n",
    "    \n",
    "    y_lower = 10\n",
    "    sample_silhouette_values = silhouette_samples(df, kmeans_labels) # Compute the silhouette scores for each sample\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[kmeans_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # Label the silhouette plots with their cluster numbers at the middle\n",
    "        y_lower = y_upper + 10  # Compute the new y_lower for next plot. 10 for the 0 samples\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "def silhouette(kmeans_dict, df, plot=False):\n",
    "    df = df.to_numpy()\n",
    "    avg_dict = dict()\n",
    "    for n_clusters, kmeans in kmeans_dict.items():      \n",
    "        kmeans_labels = kmeans.predict(df)\n",
    "        silhouette_avg = silhouette_score(df, kmeans_labels) # Average Score for all Samples\n",
    "        avg_dict.update( {silhouette_avg : n_clusters} )\n",
    "    \n",
    "        if(plot): plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running Kmeans\n",
    "# k = 8\n",
    "# kmeans_results = run_KMeans(k, final_df)\n",
    "\n",
    "# # Plotting Silhouette Analysis\n",
    "# #silhouette(kmeans_results, final_df, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KMeans(max_k, data):\n",
    "    kmeans_results = dict()\n",
    "    for k in range(2 , max_k):\n",
    "        kmeans = cluster.KMeans(n_clusters = k\n",
    "                               , init = 'k-means++'\n",
    "                               , n_init = 10\n",
    "                               , max_iter = 300\n",
    "                               , random_state = 42)\n",
    "        kmeans_results[k] = kmeans.fit(data)\n",
    "    return kmeans_results\n",
    "\n",
    "max_k = 10\n",
    "kmeans_results = run_KMeans(max_k, final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "Now we can choose the best number of K and take a deeper look at each cluster. Looking at the plots above, we have some clues that when K = 5 is when the clusters are best defined. So first we will use a simple histogram to look at the most dominant words in each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices for each cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
    "        features = vectorizer.get_feature_names()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def plotWords(dfs, n_feats):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(0, len(dfs)):\n",
    "        plt.title((\"Most Common Words in Cluster {}\".format(i)), fontsize=10, fontweight='bold')\n",
    "        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_result = 5\n",
    "# kmeans = kmeans_results.get(best_result)\n",
    "\n",
    "# final_df_array = final_df.to_numpy()\n",
    "# prediction = kmeans.predict(final_df)\n",
    "# n_feats = 20\n",
    "# dfs = get_top_features_cluster(final_df_array, prediction, n_feats)\n",
    "# plotWords(dfs, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 rows\n",
      "          0         1         2    3    4    5         6         7    \\\n",
      "मतव  0.682286  0.000000  0.264788  0.0  0.0  0.0  0.000000  0.000000   \n",
      "आल   0.605069  0.000000  0.313094  0.0  0.0  0.0  0.000000  0.000000   \n",
      "अम   0.282806  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.000000   \n",
      "दर   0.217668  0.078083  0.000000  0.0  0.0  0.0  0.116900  0.138207   \n",
      "रह   0.147901  0.000000  0.139149  0.0  0.0  0.0  0.086652  0.000000   \n",
      "\n",
      "          8    9    ...       790       791  792       793       794  795  \\\n",
      "मतव  0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
      "आल   0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
      "अम   0.000000  0.0  ...  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
      "दर   0.418796  0.0  ...  0.000000  0.000000  0.0  0.000000  0.393158  0.0   \n",
      "रह   0.000000  0.0  ...  0.112771  0.103315  0.0  0.321609  0.058286  0.0   \n",
      "\n",
      "     796     797  798       799  \n",
      "मतव  0.0  0.0000  0.0  0.000000  \n",
      "आल   0.0  0.0000  0.0  0.000000  \n",
      "अम   0.0  0.0000  0.0  0.000000  \n",
      "दर   0.0  0.0268  0.0  0.124435  \n",
      "रह   0.0  0.0000  0.0  0.000000  \n",
      "\n",
      "[5 rows x 800 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Perform TF-IDF on the 'lyrics_lemmatized' column\n",
    "X = vectorizer.fit_transform(data['lyrics_lemmatized'])\n",
    "\n",
    "# Check if the vectorizer was fitted correctly\n",
    "if not hasattr(vectorizer, 'vocabulary_'):\n",
    "    print(\"The vectorizer was not fitted correctly.\")\n",
    "else:\n",
    "    # Convert the result to a DataFrame\n",
    "    tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Assign the DataFrame to final_df\n",
    "    final_df = tf_idf\n",
    "\n",
    "    # Print the number of rows in the DataFrame\n",
    "    print(\"{} rows\".format(final_df.shape[0]))\n",
    "\n",
    "    # Print the 5 largest values in the first row\n",
    "    print(final_df.T.nlargest(5, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map of Words\n",
    "\n",
    "Now that we can look at the graphs above and see the best scored words in each cluster, it's also interesting to make it prettier by making a map of words of each cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms a centroids dataframe into a dictionary to be used on a WordCloud.\n",
    "def centroidsDict(centroids, index):\n",
    "    a = centroids.T[index].sort_values(ascending = False).reset_index().values\n",
    "    centroid_dict = dict()\n",
    "\n",
    "    for i in range(0, len(a)):\n",
    "        centroid_dict.update( {a[i,0] : a[i,1]} )\n",
    "\n",
    "    return centroid_dict\n",
    "\n",
    "def generateWordClouds(centroids):\n",
    "    wordcloud = WordCloud(max_font_size=100, background_color = 'white')\n",
    "    for i in range(0, len(centroids)):\n",
    "        centroid_dict = centroidsDict(centroids, i)        \n",
    "        wordcloud.generate_from_frequencies(centroid_dict)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title('Cluster {}'.format(i))\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroids = pd.DataFrame(kmeans.cluster_centers_)\n",
    "# centroids.columns = final_df.columns\n",
    "# generateWordClouds(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for k=2:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'WordCloud' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_482032/2312206091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Generate word clouds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgenerateWordClouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Add any other analysis you want to perform for each k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_482032/3477830141.py\u001b[0m in \u001b[0;36mgenerateWordClouds\u001b[0;34m(centroids)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerateWordClouds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_font_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcentroid_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentroidsDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WordCloud' is not defined"
     ]
    }
   ],
   "source": [
    "for k, kmeans in kmeans_results.items():\n",
    "    print(f\"Results for k={k}:\")\n",
    "    \n",
    "    # Get the centroids\n",
    "    centroids = pd.DataFrame(kmeans.cluster_centers_)\n",
    "    centroids.columns = final_df.columns\n",
    "    \n",
    "    # Generate word clouds\n",
    "    generateWordClouds(centroids)\n",
    "    \n",
    "    # Add any other analysis you want to perform for each k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing our final groups for visualization\n",
    "\n",
    "Now that we're satisfied with our clustering we should assign which country belongs to which group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the cluster labels to each country\n",
    "labels = kmeans.labels_ \n",
    "data['label'] = labels\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization the Clustered Countries in a Map\n",
    "\n",
    "Now that we have our final grouping it would be really cool to visualize it in a interactive map. To do this we'll use the awesome Folium library to see our interactive map!\n",
    "\n",
    "We'll load a geojson file of polygons and country codes with geopandas and merge it with the labelled dataframe from the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Viz\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "# Loading countries polygons\n",
    "geo_path = 'datasets/world-countries.json'\n",
    "country_geo = json.load(open(geo_path))\n",
    "gpf = gpd.read_file(geo_path)\n",
    "\n",
    "# Merging on the alpha-3 country codes\n",
    "merge = pd.merge(gpf, data, left_on='id', right_on='alpha-3')\n",
    "data_to_plot = merge[[\"id\", \"name\", \"label\", \"geometry\"]]\n",
    "\n",
    "data_to_plot.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a color_step for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import branca.colormap as cm\n",
    "\n",
    "# Creating a discrete color map\n",
    "values = data_to_plot[['label']].to_numpy()\n",
    "color_step = cm.StepColormap(['r', 'y','g','b', 'm'], vmin=values.min(), vmax=values.max(), caption='step')\n",
    "\n",
    "color_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Painting the Groups into a Choropleth Map\n",
    "\n",
    "Now that we have all the information that we want to plot into a Dataframe, we'll create a function that makes a Choropleth Map to be displayed on a folium map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from branca.element import Figure\n",
    "\n",
    "def make_geojson_choropleth(display, data, colors):\n",
    "    '''creates geojson choropleth map using a colormap, with tooltip for country names and groups'''\n",
    "    group_dict = data.set_index('id')['label'] # Dictionary of Countries IDs and Clusters\n",
    "    tooltip = folium.features.GeoJsonTooltip([\"name\", \"label\"], aliases=display, labels=True)\n",
    "    return folium.GeoJson(data[[\"id\", \"name\",\"label\",\"geometry\"]],\n",
    "                          style_function = lambda feature: {\n",
    "                               'fillColor': colors(group_dict[feature['properties']['id']]),\n",
    "                               #'fillColor': test(feature),\n",
    "                               'color':'black',\n",
    "                               'weight':0.5\n",
    "                               },\n",
    "                          highlight_function = lambda x: {'weight':2, 'color':'black'},\n",
    "                          smooth_factor=2.0,\n",
    "                          tooltip = tooltip)\n",
    "\n",
    "# Makes map appear inline on notebook\n",
    "def display(m, width, height):\n",
    "    \"\"\"Takes a folium instance and embed HTML.\"\"\"\n",
    "    fig = Figure(width=width, height=height)\n",
    "    fig.add_child(m)\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our Folium Map\n",
    "m = folium.Map(location=[43.5775, -10.106111], zoom_start=2.3, tiles='cartodbpositron')\n",
    "\n",
    "# Making a choropleth map with geojson\n",
    "geojson_choropleth = make_geojson_choropleth([\"Country:\", \"Group:\"], data_to_plot, color_step)\n",
    "geojson_choropleth.add_to(m)\n",
    "\n",
    "width, height = 1300, 675\n",
    "display(m, width, height)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
